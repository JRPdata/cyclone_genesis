{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a972b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# EXPERIMENTAL\n",
    "# Work in progress (do not use)\n",
    "\n",
    "# find TC genesis from models based on work similar to FSU's methodology\n",
    "\n",
    "# only focused on 1. so far:\n",
    "# 1. https://journals.ametsoc.org/view/journals/wefo/28/6/waf-d-13-00008_1.xml\n",
    "# 2. https://journals.ametsoc.org/view/journals/wefo/31/3/waf-d-15-0157_1.xml?tab_body=fulltext-display\n",
    "# 3. https://journals.ametsoc.org/view/journals/wefo/32/1/waf-d-16-0072_1.xml\n",
    "\n",
    "# partial TODO\n",
    "#    extend/generalize to other models\n",
    "#        all other models are parameter split gribs\n",
    "#             including another source for NAVGEM which has 850 relative vorticity\n",
    "#        refactor code for lat/lons\n",
    "#             check don't need separate lat lons for each variable (same resolution or array shape))\n",
    "#    get max 10m speed if available\n",
    "#        87:10 metre U wind component:m s**-1 (instant):regular_ll:heightAboveGround:level 10 m:fcst time 96 hrs:from 202310190600\n",
    "#        88:10 metre V wind component:m s**-1 (instant):regular_ll:heightAboveGround:level 10 m:fcst time 96 hrs:from 202310190600\n",
    "#    save TC output to JSON\n",
    "#    extend to handle multiple timesteps/bufrs\n",
    "#        individually a single criteria being met is a disturbance,\n",
    "#             start of 24 continuous hours of meeting criteriais a tc\n",
    "#    automatically download model files (UKMET seems infeasible as it costs much money)\n",
    "\n",
    "# thresholds for disturbances (reversed from text output from FSU)\n",
    "disturbance_thresholds_path = 'disturbance_thresholds.json'\n",
    "\n",
    "# shape file for placing lat,lon in basins which we are classifying\n",
    "# each has an attribute called 'basin_name', with CPAC & EPAC combined as EPAC\n",
    "# basins are NATL, EPAC, WPAC, IO, SH\n",
    "shape_file = 'shapes/basins.shp'\n",
    "\n",
    "# Test the function with your GRIB file\n",
    "# NAVGEM 96h\n",
    "# uses regular_ll\n",
    "\n",
    "#grib_file = \"navgem_2023101906f096.grib2\"\n",
    "# cgi combined all relevant?\n",
    "# the new was with cgi but it gets TOO much information (it gets 11 parameters rather than 9: u/v wind for 200 we don't need)\n",
    "##### grib_file = \"/home/db/metview/JRPdata/gfs/gfs.t00z.pgrb2.0p25.f000_new\"\n",
    "#   use the index file\n",
    "#grib_file = \"/home/db/metview/JRPdata/navgem2/US058GMET-GR1mdl.0018_0056_09600F0OF2023101906_0100_008500-000000geop_ht\"\n",
    "#grib_file = \"/home/db/metview/JRPdata/ukmet/isbl_geopotential-height_85000.0_2023102112_12.grib\"\n",
    "\n",
    "# only tested the unified grib with the NAV model (as the NCEP NAV grib data is unified)\n",
    "model_name = 'NAV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bda312c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrib\n",
    "import re\n",
    "import math\n",
    "from metpy.units import units\n",
    "import metpy.calc as mpcalc\n",
    "import numpy as np\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# may need to modify lzma.py in python folder to get this to work (pip install backports-lzma)\n",
    "# this is for metpy\n",
    "try:\n",
    "    import lzma\n",
    "except ImportError:\n",
    "    import backports.lzma as lzma\n",
    "\n",
    "gdf = gpd.read_file(shape_file)\n",
    "\n",
    "disturbance_criteria_names_map = {\n",
    "    'WS': 'vmax925',\n",
    "    'THKN': 'gp250_850_thickness',\n",
    "    'RV': 'rv850max'\n",
    "}\n",
    "\n",
    "# shape file attribute names to threshold names\n",
    "shape_basin_names_to_threshold_names_map = {\n",
    "    'NATL': 'AL',\n",
    "    'WPAC': 'WP',\n",
    "    'IO': 'IO',\n",
    "    'SH': 'SH',\n",
    "    'EPAC': 'EP'\n",
    "}\n",
    "\n",
    "with open(disturbance_thresholds_path, 'r') as f:\n",
    "    disturbance_thresholds = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fedfd205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# todo: the calculations using neighborhoods don't wrap around at lons (and lats) and they should\n",
    "#  for instance, the unsigned lats array starts at 0 degrees and ends at 360\n",
    "\n",
    "def list_available_parameters(grib_file):\n",
    "    try:\n",
    "        # Open the GRIB file\n",
    "        grbs = pygrib.open(grib_file)\n",
    "\n",
    "        # Initialize a list to store parameter information\n",
    "        parameter_info = []\n",
    "\n",
    "        # Iterate through the GRIB messages and extract parameter information\n",
    "        for grb in grbs:\n",
    "            parameter_name = grb.name\n",
    "            parameter_unit = grb.units\n",
    "            level_type = grb.levelType\n",
    "            level = grb.level\n",
    "            print(grb)\n",
    "            parameter_info.append({\n",
    "                \"Parameter Name\": parameter_name,\n",
    "                \"Unit\": parameter_unit,\n",
    "                \"Level Type\": level_type,\n",
    "                \"Level\": level\n",
    "            })\n",
    "\n",
    "        # Close the GRIB file\n",
    "        grbs.close()\n",
    "\n",
    "        # Print the information for parameters\n",
    "        for info in parameter_info:\n",
    "            print(\"Parameter Name:\", info[\"Parameter Name\"])\n",
    "            print(\"Unit:\", info[\"Unit\"])\n",
    "            print(\"Level Type:\", info[\"Level Type\"])\n",
    "            print(\"Level:\", info[\"Level\"])\n",
    "            print(\"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def load_and_extract_unified_grib_data(grib_file):\n",
    "    try:\n",
    "        # Open the GRIB file\n",
    "        grbs = pygrib.open(grib_file)\n",
    "\n",
    "        # Initialize variables for relevant parameters\n",
    "        mslp = None\n",
    "        u_wind_925 = None\n",
    "        v_wind_925 = None\n",
    "        u_wind_850 = None\n",
    "        v_wind_850 = None\n",
    "        geopotential_250 = None\n",
    "        geopotential_850 = None\n",
    "        \n",
    "        mslp_units = None\n",
    "        wind_925_units = None\n",
    "        \n",
    "        mslp_lats = None\n",
    "        mslp_lons = None\n",
    "        u_wind_925_lats = None\n",
    "        u_wind_925_lons = None\n",
    "        v_wind_925_lats = None\n",
    "        v_wind_925_lons = None\n",
    "        u_wind_850_lats = None\n",
    "        u_wind_850_lons = None\n",
    "        v_wind_850_lats = None\n",
    "        v_wind_850_lons = None\n",
    "        geopotential_250_lats = None\n",
    "        geopotential_250_lons = None\n",
    "        geopotential_850_lats = None\n",
    "        geopotential_850_lons = None\n",
    "        \n",
    "        grid_resolution = {}\n",
    "        \n",
    "        # Extract relevant parameters (modify the parameter names and levels accordingly)\n",
    "        for grb in grbs:\n",
    "            if grb.name == 'Pressure reduced to MSL' and grb.level == 0:\n",
    "                mslp = grb.values\n",
    "                mslp_units = grb.units\n",
    "                mslp_lats, mslp_lons = grb.latlons()\n",
    "                grid_resolution['mslp'] = grb['iDirectionIncrementInDegrees']\n",
    "            elif grb.name == 'U component of wind' and grb.level == 925:\n",
    "                u_wind_925 = grb.values\n",
    "                wind_925_units = grb.units\n",
    "                u_wind_925_lats, u_wind_925_lons = grb.latlons()\n",
    "                grid_resolution['uwind925'] = grb['iDirectionIncrementInDegrees']\n",
    "            elif grb.name == 'V component of wind' and grb.level == 925:\n",
    "                v_wind_925 = grb.values\n",
    "                v_wind_925_lats, v_wind_925_lons = grb.latlons()\n",
    "                grid_resolution['vwind925'] = grb['iDirectionIncrementInDegrees']\n",
    "            elif grb.name == 'U component of wind' and grb.level == 850:\n",
    "                u_wind_850 = grb.values\n",
    "                wind_850_units = grb.units\n",
    "                u_wind_850_lats, u_wind_850_lons = grb.latlons()\n",
    "                grid_resolution['uwind850'] = grb['iDirectionIncrementInDegrees']\n",
    "            elif grb.name == 'V component of wind' and grb.level == 850:\n",
    "                v_wind_850 = grb.values\n",
    "                v_wind_850_lats, v_wind_850_lons = grb.latlons()\n",
    "                grid_resolution['vwind850'] = grb['iDirectionIncrementInDegrees']\n",
    "            elif grb.name == 'Geopotential Height' and grb.level == 250:\n",
    "                geopotential_250 = grb.values\n",
    "                geopotential_250_lats, geopotential_250_lons = grb.latlons()\n",
    "                grid_resolution['gh250'] = grb['iDirectionIncrementInDegrees']\n",
    "            elif grb.name == 'Geopotential Height' and grb.level == 850:\n",
    "                geopotential_850 = grb.values\n",
    "                geopotential_850_lats, geopotential_850_lons = grb.latlons()\n",
    "                grid_resolution['gh850'] = grb['iDirectionIncrementInDegrees']\n",
    "\n",
    "        # Close the GRIB file\n",
    "        grbs.close()\n",
    "\n",
    "\n",
    "        # Check if units are not in hPa and convert if necessary\n",
    "        if mslp_units != \"hPa\":\n",
    "            print(f\"Converting MSLP units from {mslp_units} to hPa\")\n",
    "            if mslp_units == \"Pa\":\n",
    "                # Convert from Pa to hPa\n",
    "                mslp *= 0.01\n",
    "                mslp_units = \"hPa\"\n",
    "            else:\n",
    "                print(\"Warning: Units of MSLP are not in Pa or hPa. Please verify the units for accurate results.\")\n",
    "\n",
    "        # Check if units are not in m/s for 925 hPa wind components and convert if necessary\n",
    "        if not (re.search(r\"(m/s|m s\\*\\*-1)\", wind_925_units)):\n",
    "            print(f\"Converting 925 hPa wind components units from {wind_925_units} to m/s\")\n",
    "            if re.search(r\"knots|knot\", wind_925_units, re.I):\n",
    "                # Convert from knots to m/s (1 knot ≈ 0.514444 m/s)\n",
    "                u_wind_925 *= 0.514444\n",
    "                v_wind_925 *= 0.514444\n",
    "                wind_925_units = \"m/s\"\n",
    "            else:\n",
    "                print(\"Warning: Units of 925 hPa wind components are not in knots, m/s, or m s**-1. Please verify the units for accurate results.\")\n",
    "                \n",
    "        # Check if units are not in m/s for 925 hPa wind components and convert if necessary\n",
    "        if not (re.search(r\"(m/s|m s\\*\\*-1)\", wind_850_units)):\n",
    "            print(f\"Converting 850 hPa wind components units from {wind_850_units} to m/s\")\n",
    "            if re.search(r\"knots|knot\", wind_925_units, re.I):\n",
    "                # Convert from knots to m/s (1 knot ≈ 0.514444 m/s)\n",
    "                u_wind_850 *= 0.514444\n",
    "                v_wind_850 *= 0.514444\n",
    "                wind_850_units = \"m/s\"\n",
    "            else:\n",
    "                print(\"Warning: Units of 925 hPa wind components are not in knots, m/s, or m s**-1. Please verify the units for accurate results.\")\n",
    "        \n",
    "        return grid_resolution, mslp_units, mslp, mslp_lats, mslp_lons, wind_925_units, u_wind_925, u_wind_925_lats, u_wind_925_lons, v_wind_925, v_wind_925_lats, v_wind_925_lons, wind_850_units, u_wind_850, u_wind_850_lats, u_wind_850_lons, v_wind_850, v_wind_850_lats, v_wind_850_lons, geopotential_250, geopotential_250_lats, geopotential_250_lons, geopotential_850, geopotential_850_lats, geopotential_850_lons\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "def convert_to_signed_lon(lon):\n",
    "    # Convert longitudes from 0-360 range to -180 to +180 range\n",
    "    return (lon + 180) % 360 - 180\n",
    "\n",
    "\n",
    "def calculate_neighborhood_size(degree_radius, grid_resolution):\n",
    "    # Calculate the radius in grid points\n",
    "    radius_in_grid_points = int(degree_radius / grid_resolution)\n",
    "\n",
    "    # Calculate the neighborhood size\n",
    "    neighborhood_size = 2 * radius_in_grid_points + 1  # Assuming a square neighborhood\n",
    "\n",
    "    return neighborhood_size\n",
    "\n",
    "def array_indices_to_lat_lon(x, y, mslp_lats, mslp_lons):\n",
    "    lat = mslp_lats[x, y]\n",
    "    lon = mslp_lons[x, y]\n",
    "    signed_lon = convert_to_signed_lon(lon)\n",
    "    return lat, signed_lon\n",
    "\n",
    "# print candidates\n",
    "def print_candidates(mslp_minima_list, mslp_lats = None, mslp_lons = None, meet_all_disturbance_thresholds = False):\n",
    "    n = 0\n",
    "    for candidate in mslp_minima_list:\n",
    "        if meet_all_disturbance_thresholds:\n",
    "            if not candidate['criteria']['all']:\n",
    "                continue\n",
    "                \n",
    "\n",
    "        basin_str = \"\"\n",
    "        if 'basin' in candidate:\n",
    "            basin = candidate['basin']\n",
    "            basin_str += f'{basin} Basin, '\n",
    "        \n",
    "        n += 1\n",
    "        mslp_value = candidate[\"mslp_value\"]\n",
    "        \n",
    "        if mslp_lats is not None and mslp_lons is not None:\n",
    "            x = candidate[\"x_value\"]\n",
    "            y = candidate[\"y_value\"]\n",
    "            lat, lon = array_indices_to_lat_lon(x, y, mslp_lats, mslp_lons)\n",
    "        else:\n",
    "            lat = candidate['lat']\n",
    "            lon = candidate['lon']\n",
    "            \n",
    "        formatted_mslp = f\"{mslp_value:.1f}\".rjust(6, ' ')\n",
    "        rv_str = \"\"\n",
    "        if 'rv850max'in candidate:\n",
    "            rv_str = \", 850 RV MAX (*10^-5 1/s): \"\n",
    "            rv_value = candidate['rv850max'] * np.power(10.0,5)\n",
    "            formatted_rv = f\"{rv_value:2.2f}\".rjust(5, ' ')\n",
    "            rv_str += formatted_rv\n",
    "        \n",
    "        thickness_str = \"\"\n",
    "        if 'gp250_850_thickness' in candidate:\n",
    "            thickness_str = \", 250-850 hPa Thickness (m): \"\n",
    "            thickness_value = candidate['gp250_850_thickness']\n",
    "            formatted_thickness = f\"{thickness_value:2.2f}\".rjust(6, ' ')\n",
    "            thickness_str += formatted_thickness\n",
    "        \n",
    "        vmax_str = \"\"\n",
    "        if 'vmax925' in candidate:\n",
    "            vmax_str = \", 925 hPa WS MAX (m/s): \"\n",
    "            vmax_value = candidate['vmax925']\n",
    "            formatted_vmax = f\"{vmax_value:3.2f}\".rjust(6, ' ')\n",
    "            vmax_str += formatted_vmax\n",
    "        \n",
    "        print(f\"#{n: >2}, {basin_str}Latitude (deg): {lat: >6}, Longitude (deg): {lon: >6}, MSLP (hPa): {formatted_mslp}{rv_str}{thickness_str}{vmax_str}\")\n",
    "\n",
    "# this function is for checking find_mslp_minima_with_closed_isobars\n",
    "def find_mslp_minima(mslp_data, minima_neighborhood_size=3):\n",
    "    try:\n",
    "        # Lists to store MSLP minima, latitudes, and longitudes\n",
    "        candidates = []\n",
    "\n",
    "        # Loop through each grid point\n",
    "        for x in range(minima_neighborhood_size, mslp_data.shape[0] - minima_neighborhood_size):\n",
    "            for y in range(minima_neighborhood_size, mslp_data.shape[1] - minima_neighborhood_size):\n",
    "                mslp_value = mslp_data[x, y]  # MSLP value at the current point\n",
    "                neighborhood = mslp_data[x - minima_neighborhood_size:x + minima_neighborhood_size + 1,\n",
    "                                         y - minima_neighborhood_size:y + minima_neighborhood_size + 1]\n",
    "\n",
    "                # Check if the MSLP value is the minimum within the neighborhood\n",
    "                if mslp_value == neighborhood.min():\n",
    "                    candidate = {\n",
    "                        \"mslp_value\": mslp_value,\n",
    "                        \"x_value\": x,\n",
    "                        \"y_value\": y\n",
    "                    }\n",
    "                    candidates.append(candidate)\n",
    "\n",
    "\n",
    "        return candidates\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return [], [], []\n",
    "\n",
    "def find_mslp_minima_with_closed_isobars(mslp_data, grid_resolution, minima_neighborhood_size=3, isobar_threshold=2.0, isobar_search_radius_degrees = 5):\n",
    "    isobar_neighborhood_size = calculate_neighborhood_size(isobar_search_radius_degrees, grid_resolution)\n",
    "    \n",
    "    def dfs(x, y):\n",
    "        # Depth-first search to find a closed path\n",
    "        nonlocal path_found\n",
    "        visited[x][y] = True\n",
    "\n",
    "        for dx in range(-1, 2):\n",
    "            for dy in range(-1, 2):\n",
    "                nx, ny = x + dx, y + dy\n",
    "\n",
    "                if 0 <= nx < isobar_neighborhood_size * 2 + 1 and 0 <= ny < isobar_neighborhood_size * 2 + 1 and not visited[nx][ny]:\n",
    "                    if neighborhood_modified[nx][ny] >= 0:\n",
    "                        if nx == 0 or ny == 0 or nx == isobar_neighborhood_size * 2 or ny == isobar_neighborhood_size * 2:\n",
    "                            path_found = True\n",
    "                            return\n",
    "                        dfs(nx, ny)\n",
    "\n",
    "    try:\n",
    "        # List to store MSLP minima as dictionaries\n",
    "        mslp_minima_list = []\n",
    "\n",
    "        # Create a list of candidates for MSLP minima\n",
    "        candidates = []\n",
    "\n",
    "        # Loop through each grid point\n",
    "        for x in range(minima_neighborhood_size, mslp_data.shape[0] - minima_neighborhood_size):\n",
    "            for y in range(minima_neighborhood_size, mslp_data.shape[1] - minima_neighborhood_size):\n",
    "                mslp_value = mslp_data[x, y]  # MSLP value at the current point\n",
    "                neighborhood = mslp_data[x - minima_neighborhood_size:x + minima_neighborhood_size + 1,\n",
    "                                         y - minima_neighborhood_size:y + minima_neighborhood_size + 1]\n",
    "\n",
    "                # Check if the MSLP value is the minimum within the neighborhood\n",
    "                if mslp_value == neighborhood.min():\n",
    "                    candidates.append((x, y, mslp_value))\n",
    "\n",
    "        # Loop through the candidates to find isobars\n",
    "        for x, y, minima_value in candidates:\n",
    "            # Create a modified neighborhood for isobar calculation\n",
    "            x_min = max(0, x - isobar_neighborhood_size)\n",
    "            x_max = min(mslp_data.shape[0], x + isobar_neighborhood_size + 1)\n",
    "            y_min = max(0, y - isobar_neighborhood_size)\n",
    "            y_max = min(mslp_data.shape[1], y + isobar_neighborhood_size + 1)\n",
    "\n",
    "            neighborhood_modified = mslp_data[x_min:x_max, y_min:y_max] - minima_value - isobar_threshold\n",
    "\n",
    "            # Initialize visited array for DFS\n",
    "            visited = np.zeros_like(neighborhood_modified, dtype=bool)\n",
    "\n",
    "            # Flag to track if a closed path is found\n",
    "            path_found = False\n",
    "\n",
    "            # Start DFS from the center of the neighborhood\n",
    "            dfs(x - x_min, y - y_min)\n",
    "\n",
    "            if path_found:\n",
    "                # Store MSLP minima data as a dictionary\n",
    "                candidate = {\n",
    "                    \"mslp_value\": minima_value,\n",
    "                    \"x_value\": x,\n",
    "                    \"y_value\": y\n",
    "                }\n",
    "                mslp_minima_list.append(candidate)\n",
    "\n",
    "        return mslp_minima_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []\n",
    "\n",
    "# calculate vorticity (accounting for projection distortion) using metpy (uses finite differences method)\n",
    "# returns vorticity using an ellipsoid based on WGS84\n",
    "def calculate_vorticity(u_wind_850, v_wind_850, mslp_lats, mslp_lons):\n",
    "    # Calculate grid spacing distances (these will be the dx and dy values used for calculating vorticity)\n",
    "    ellipsoid = pyproj.Geod(ellps=\"WGS84\")\n",
    "    mslp_dx, mslp_dy = mpcalc.lat_lon_grid_deltas(mslp_lons * units.degrees, mslp_lats * units.degrees, geod=ellipsoid)\n",
    "\n",
    "    # Convert wind components to units\n",
    "    u_wind_850_with_units = units.Quantity(u_wind_850, 'm/s')\n",
    "    v_wind_850_with_units = units.Quantity(v_wind_850, 'm/s')\n",
    "\n",
    "    # Calculate relative vorticity (use WGS84)\n",
    "    vort_850 = np.array(mpcalc.vorticity(u_wind_850_with_units, v_wind_850_with_units, dx=mslp_dx, dy=mslp_dy))\n",
    "\n",
    "    return vort_850\n",
    "\n",
    "# Function to find RV maximums in neighborhoods for a list of candidates\n",
    "def find_rv_maximums_in_neighborhoods(mslp_minima_list, rv, grid_resolution, relative_vorticity_radius_degrees = 2):\n",
    "    rv_neighborhood_size = calculate_neighborhood_size(relative_vorticity_radius_degrees, grid_resolution)\n",
    "    updated_mslp_minima_list = []\n",
    "\n",
    "    for candidate in mslp_minima_list:\n",
    "        x, y, _ = candidate[\"x_value\"], candidate[\"y_value\"], candidate[\"mslp_value\"]\n",
    "\n",
    "        # Extract the neighborhood for the current candidate\n",
    "        x_min = max(0, x - rv_neighborhood_size)\n",
    "        x_max = min(rv.shape[0], x + rv_neighborhood_size + 1)\n",
    "        y_min = max(0, y - rv_neighborhood_size)\n",
    "        y_max = min(rv.shape[1], y + rv_neighborhood_size + 1)\n",
    "        neighborhood = rv[x_min:x_max, y_min:y_max]\n",
    "\n",
    "        # Find the maximum RV value within the neighborhood\n",
    "        rv_max = neighborhood.max()\n",
    "\n",
    "        # Update a copy of the candidate's dictionary with rv maximum value\n",
    "        updated_candidate = candidate.copy()\n",
    "        updated_candidate[\"rv850max\"] = rv_max\n",
    "\n",
    "        # Add the updated candidate to the list\n",
    "        updated_mslp_minima_list.append(updated_candidate)\n",
    "\n",
    "    return updated_mslp_minima_list\n",
    "    \n",
    "# calculate relative max thickness for 250hPa - 850hPa for a list of candidates\n",
    "def find_gp_250_850_max_thickness(mslp_minima_list, geopotential_250, geopotential_850, grid_resolution, degrees_radius=2):\n",
    "    # Calculate the neighborhood size based on degrees_radius and grid_resolution\n",
    "    neighborhood_size = calculate_neighborhood_size(degrees_radius, grid_resolution)\n",
    "\n",
    "    updated_mslp_minima_list = []\n",
    "    \n",
    "    # Get the shape of the geopotential arrays\n",
    "    array_shape = geopotential_250.shape\n",
    "\n",
    "    # Iterate over the list of candidates\n",
    "    for candidate in mslp_minima_list:\n",
    "        # Extract the x and y indices of the candidate\n",
    "        x_index, y_index = candidate['x_value'], candidate['y_value']\n",
    "\n",
    "        # Calculate the neighborhood bounds\n",
    "        x_start = max(0, x_index - neighborhood_size)\n",
    "        x_end = min(array_shape[0] - 1, x_index + neighborhood_size)\n",
    "        y_start = max(0, y_index - neighborhood_size)\n",
    "        y_end = min(array_shape[1] - 1, y_index + neighborhood_size)\n",
    "\n",
    "        # Extract the neighborhoods for 250 hPa and 850 hPa\n",
    "        neighborhood_250 = geopotential_250[x_start:x_end + 1, y_start:y_end + 1]\n",
    "        neighborhood_850 = geopotential_850[x_start:x_end + 1, y_start:y_end + 1]\n",
    "\n",
    "        # Calculate the 250–850-hPa thickness for each cell in the neighborhood\n",
    "        thickness = neighborhood_250 - neighborhood_850\n",
    "\n",
    "        # Find the maximum thickness value in the neighborhood\n",
    "        max_thickness = thickness.max()\n",
    "\n",
    "        # Update a copy of the candidate's dictionary with the maximum thickness value\n",
    "        updated_candidate = candidate.copy()\n",
    "        updated_candidate['gp250_850_thickness'] = max_thickness\n",
    "        \n",
    "        # Add the updated candidate to the list\n",
    "        updated_mslp_minima_list.append(updated_candidate)\n",
    "\n",
    "    return updated_mslp_minima_list\n",
    "\n",
    "# find max wind at 925 hPa for a list of candidates\n",
    "def find_max_wind_925(mslp_minima_list, u_wind_925, v_wind_925, grid_resolution, degrees_radius=5):\n",
    "    # Calculate the neighborhood size based on radius_degrees and grid_resolution for wind\n",
    "    neighborhood_size = calculate_neighborhood_size(degrees_radius, grid_resolution)\n",
    "\n",
    "    updated_mslp_minima_list = []\n",
    "    \n",
    "    # Get the shape of the wind arrays\n",
    "    array_shape = u_wind_925.shape\n",
    "\n",
    "    # Iterate over the list of candidates\n",
    "    for candidate in mslp_minima_list:\n",
    "        # Extract the x and y indices of the candidate\n",
    "        x_index = candidate['x_value']\n",
    "        y_index = candidate['y_value']\n",
    "\n",
    "        # Calculate the neighborhood bounds\n",
    "        x_start = max(0, x_index - neighborhood_size)\n",
    "        x_end = min(array_shape[0] - 1, x_index + neighborhood_size)\n",
    "        y_start = max(0, y_index - neighborhood_size)\n",
    "        y_end = min(array_shape[1] - 1, y_index + neighborhood_size)\n",
    "\n",
    "        # Extract the neighborhoods for u-wind and v-wind at 925 hPa\n",
    "        neighborhood_u_wind = u_wind_925[x_start:x_end + 1, y_start:y_end + 1]\n",
    "        neighborhood_v_wind = v_wind_925[x_start:x_end + 1, y_start:y_end + 1]\n",
    "\n",
    "        # Calculate wind speed in the neighborhood\n",
    "        wind_speed = np.sqrt(neighborhood_u_wind ** 2 + neighborhood_v_wind ** 2)\n",
    "\n",
    "        # Find the maximum wind speed value in the neighborhood\n",
    "        max_wind_speed = wind_speed.max()\n",
    "\n",
    "        # Update a copy of the candidate's dictionary with the maximum wind speed value\n",
    "        updated_candidate = candidate.copy()\n",
    "        updated_candidate['vmax925'] = max_wind_speed\n",
    "        \n",
    "        # Add the updated candidate to the list\n",
    "        updated_mslp_minima_list.append(updated_candidate)\n",
    "\n",
    "    return updated_mslp_minima_list\n",
    "\n",
    "# add basin name, and also removes candidates that aren't in one of the basins\n",
    "def add_basin_name(mslp_minima_list, mslp_lats, mslp_lons):\n",
    "    updated_mslp_minima_list = []\n",
    "\n",
    "    for candidate in mslp_minima_list:\n",
    "        x = candidate[\"x_value\"]\n",
    "        y = candidate[\"y_value\"]\n",
    "\n",
    "        lat, lon = array_indices_to_lat_lon(x, y, mslp_lats, mslp_lons)\n",
    "        basin_name = get_basin_name_from_lat_lon(lat, lon)\n",
    "        \n",
    "        # remove candidate if not in a basin we are considering\n",
    "        if not basin_name:\n",
    "            continue\n",
    "\n",
    "        # Update a copy of the candidate's dictionary with rv maximum value\n",
    "        updated_candidate = candidate.copy()\n",
    "        updated_candidate['basin'] = basin_name\n",
    "        \n",
    "        updated_mslp_minima_list.append(updated_candidate)\n",
    "\n",
    "    return updated_mslp_minima_list\n",
    "\n",
    "# Function to calculate the booleans on disturbance thresholds are met or not for each criteria and for all\n",
    "# Must calculate and update with the basin classification first\n",
    "def calc_disturbance_threshold_booleans(mslp_minima_list, model_name):\n",
    "    updated_mslp_minima_list = []\n",
    "\n",
    "    for candidate in mslp_minima_list:\n",
    "        # Update a copy of the candidate's dictionary with rv maximum value\n",
    "        updated_candidate = candidate.copy()\n",
    "        all_met = True\n",
    "        \n",
    "        basin_name = candidate[\"basin\"]\n",
    "        \n",
    "        for criteria_abbrev, criteria_value in disturbance_thresholds[model_name][basin_name].items():\n",
    "            criteria_name = disturbance_criteria_names_map[criteria_abbrev]\n",
    "            if criteria_name == 'rv850max':\n",
    "                # thresholds in the JSON for RV are scaled by 10^5\n",
    "                criteria_value *= pow(10, -5)\n",
    "            criteria_bool = False\n",
    "            if updated_candidate[criteria_name] >= criteria_value:\n",
    "                criteria_bool = True\n",
    "            if 'criteria' not in updated_candidate:\n",
    "                updated_candidate['criteria'] = {}\n",
    "            updated_candidate['criteria'][criteria_name] = criteria_bool\n",
    "            all_met = (all_met and criteria_bool)\n",
    "\n",
    "        updated_candidate['criteria']['all'] = all_met\n",
    "        # Add the updated candidate to the list\n",
    "        updated_mslp_minima_list.append(updated_candidate)\n",
    "\n",
    "    return updated_mslp_minima_list\n",
    "\n",
    "# returns the basin name from lat, lon if in a basin that is covered by the thresholds, otherwise returns None\n",
    "def get_basin_name_from_lat_lon(lat, lon):\n",
    "    # Create a Point geometry for the latitude and longitude\n",
    "    point = Point(lon, lat)\n",
    "\n",
    "    # Check if the point is within any of the polygons\n",
    "    result = gdf[gdf.geometry.covers(point)]\n",
    "    if not result.empty:\n",
    "        shape_basin_name = result['basin_name'].iloc[0]\n",
    "        # this is used for thresholds so return the threshold name\n",
    "        return shape_basin_names_to_threshold_names_map[shape_basin_name]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# return with lat and lon\n",
    "# filter out candidates not meeting criteria\n",
    "def get_disturbance_candidates_from_unified_grib(grib_file):\n",
    "    grid_resolution, mslp_units, mslp, mslp_lats, mslp_lons, wind_925_units, u_wind_925, u_wind_925_lats, u_wind_925_lons, v_wind_925, v_wind_925_lats, v_wind_925_lons, wind_850_units, u_wind_850, u_wind_850_lats, u_wind_850_lons, v_wind_850, v_wind_850_lats, v_wind_850_lons, geopotential_250, geopotential_250_lats, geopotential_250_lons, geopotential_850, geopotential_850_lats, geopotential_850_lons = load_and_extract_unified_grib_data(grib_file)\n",
    "\n",
    "    shapes = [x.shape for x in\n",
    "        [\n",
    "            mslp_lats, mslp_lons, u_wind_925_lats, u_wind_925_lons, v_wind_925_lats, v_wind_925_lons,\n",
    "            u_wind_850_lats, u_wind_850_lons, v_wind_850_lats, v_wind_850_lons,\n",
    "            geopotential_250_lats, geopotential_250_lons, geopotential_850_lats, geopotential_850_lons\n",
    "        ] if x is not None]\n",
    "    \n",
    "    # check to make sure all the same shape\n",
    "    if len(set(shapes)) != 1:\n",
    "        # lats and lons different shapes!\n",
    "        print(f\"Error: getting disturbance candidates: lat,lons different shapes for: {grib_file}\")\n",
    "        return None\n",
    "    \n",
    "    # lats and lons are all the same\n",
    "    lats = mslp_lats\n",
    "    lons = mslp_lons\n",
    "    \n",
    "    mslp_minima_list = find_mslp_minima(mslp)\n",
    "\n",
    "    # this will be the candidates restricted by MSLP closed isobars only\n",
    "    mslp_minima_list_with_closed_isobars = find_mslp_minima_with_closed_isobars(mslp, grid_resolution['mslp'])\n",
    "\n",
    "    # calculate relative vorticity for the entire data set first\n",
    "    # this may issue warnings for divide by 0 for vorticity calculations\n",
    "    rv_850 = calculate_vorticity(u_wind_850, v_wind_850, mslp_lats, mslp_lons)\n",
    "    # calculate relative vorticity maximum for each candidate\n",
    "    mslp_minima_list_with_closed_isobars = find_rv_maximums_in_neighborhoods(mslp_minima_list_with_closed_isobars, rv_850, grid_resolution['gh250'])\n",
    "\n",
    "    # Find the maximum relative thickness (250 - 850 hPa) for each candidate\n",
    "    mslp_minima_list_with_closed_isobars = find_gp_250_850_max_thickness(mslp_minima_list_with_closed_isobars, geopotential_250, geopotential_850, grid_resolution['gh250'])\n",
    "\n",
    "    # find the maximum 925 hPa wind speed\n",
    "    mslp_minima_list_with_closed_isobars = find_max_wind_925(mslp_minima_list_with_closed_isobars, u_wind_925, v_wind_925, grid_resolution['uwind925'])\n",
    "\n",
    "    mslp_minima_list_in_basins = add_basin_name(mslp_minima_list_with_closed_isobars, lats, lons)\n",
    "    mslp_minima_list_with_disturbance_threshold_booleans = calc_disturbance_threshold_booleans(mslp_minima_list_in_basins, model_name)\n",
    "    # print_candidates(mslp_minima_list_with_disturbance_threshold_booleans, lats, lons, meet_all_disturbance_thresholds = True)\n",
    "\n",
    "    updated_mslp_minima_list = []\n",
    "\n",
    "    # Iterate over the list of candidates\n",
    "    for candidate in mslp_minima_list_with_disturbance_threshold_booleans:\n",
    "        # exclude candidates not meeting all criteria\n",
    "        if not candidate['criteria']['all']:\n",
    "            continue\n",
    "\n",
    "        # Update a copy of the candidate's dictionary with LAT, LON\n",
    "        updated_candidate = candidate.copy()\n",
    "        # add the LAT, LON\n",
    "        x = candidate[\"x_value\"]\n",
    "        y = candidate[\"y_value\"]\n",
    "        lat, lon = array_indices_to_lat_lon(x, y, lats, lons)\n",
    "        updated_candidate['lat'] = lat\n",
    "        updated_candidate['lon'] = lon\n",
    "        \n",
    "        # Add the updated candidate to the list\n",
    "        updated_mslp_minima_list.append(updated_candidate)\n",
    "\n",
    "    return updated_mslp_minima_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96daea96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting MSLP units from Pa to hPa\n",
      "# 1, IO Basin, Latitude (deg):   15.5, Longitude (deg):   53.5, MSLP (hPa):  992.7, 850 RV MAX (*10^-5 1/s): 49.59, 250-850 hPa Thickness (m): 9563.80, 925 hPa WS MAX (m/s):  57.83\n",
      "# 2, IO Basin, Latitude (deg):   16.0, Longitude (deg):   84.5, MSLP (hPa):  986.1, 850 RV MAX (*10^-5 1/s): 55.36, 250-850 hPa Thickness (m): 9620.60, 925 hPa WS MAX (m/s):  58.66\n",
      "# 3, AL Basin, Latitude (deg):   33.5, Longitude (deg):  -54.5, MSLP (hPa):  970.1, 850 RV MAX (*10^-5 1/s): 76.10, 250-850 hPa Thickness (m): 9682.10, 925 hPa WS MAX (m/s):  67.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/db/.local/lib/python3.9/site-packages/pint/facets/plain/quantity.py:986: RuntimeWarning: invalid value encountered in divide\n",
      "  magnitude = magnitude_op(new_self._magnitude, other._magnitude)\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "grib_file = \"navgem_2023101906f096.grib2\"\n",
    "\n",
    "#list_available_parameters(grib_file)\n",
    "\n",
    "candidates = get_disturbance_candidates_from_unified_grib(grib_file)\n",
    "print_candidates(candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d81615a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6794d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
