{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a972b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENTAL\n",
    "# Work in progress (do not use)\n",
    "\n",
    "# find TC genesis from models based on work similar to FSU's methodology\n",
    "\n",
    "# only focused on 1. so far:\n",
    "# [1] https://journals.ametsoc.org/view/journals/wefo/28/6/waf-d-13-00008_1.xml\n",
    "# [2] https://journals.ametsoc.org/view/journals/wefo/31/3/waf-d-15-0157_1.xml?tab_body=fulltext-display\n",
    "# [3] https://journals.ametsoc.org/view/journals/wefo/32/1/waf-d-16-0072_1.xml\n",
    "\n",
    "# units are metric, but scale may be mixed between internal representations of data, thresholds, and printouts\n",
    "\n",
    "# partial TODO\n",
    "#    extend/generalize to other models (NAV, GFS, ECM, CMC, UKMET need comparison to txt files)\n",
    "#        need case example for SH (Lola?)\n",
    "#        check output\n",
    "#    get max 10m speed if available\n",
    "#        87:10 metre U wind component:m s**-1 (instant):regular_ll:heightAboveGround:level 10 m:fcst time 96 hrs:from 202310190600\n",
    "#        88:10 metre V wind component:m s**-1 (instant):regular_ll:heightAboveGround:level 10 m:fcst time 96 hrs:from 202310190600\n",
    "#    save TC output to JSON\n",
    "#    extend to handle multiple timesteps/bufrs\n",
    "#        individually a single criteria being met is a disturbance,\n",
    "#             start of 24 continuous hours of meeting criteriais a tc\n",
    "#    automatically download model files (UKMET seems infeasible as it costs much money)\n",
    "\n",
    "# thresholds for disturbances (reversed from text output from FSU)\n",
    "disturbance_thresholds_path = 'disturbance_thresholds.json'\n",
    "\n",
    "# shape file for placing lat,lon in basins which we are classifying\n",
    "# each has an attribute called 'basin_name', with CPAC & EPAC combined as EPAC\n",
    "# basins are NATL, EPAC, WPAC, IO, SH\n",
    "shape_file = 'shapes/basins.shp'\n",
    "\n",
    "# for debugging MSLP isobars (depth first search)\n",
    "debug_isobar_images = False\n",
    "\n",
    "# save vorticity calculations\n",
    "debug_save_vorticity = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bda312c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pygrib\n",
    "import re\n",
    "import math\n",
    "from metpy.units import units\n",
    "import metpy.calc as mpcalc\n",
    "import numpy as np\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import traceback\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# may need to modify lzma.py in python folder to get this to work (pip install backports-lzma)\n",
    "# this is for metpy\n",
    "try:\n",
    "    import lzma\n",
    "except ImportError:\n",
    "    import backports.lzma as lzma\n",
    "\n",
    "gdf = gpd.read_file(shape_file)\n",
    "\n",
    "disturbance_criteria_names_map = {\n",
    "    'WS': 'vmax925',\n",
    "    'THKN': 'gp250_850_thickness',\n",
    "    'RV': 'rv850max'\n",
    "}\n",
    "\n",
    "# shape file attribute names to threshold names\n",
    "shape_basin_names_to_threshold_names_map = {\n",
    "    'NATL': 'AL',\n",
    "    'WPAC': 'WP',\n",
    "    'IO': 'IO',\n",
    "    'SH': 'SH',\n",
    "    'EPAC': 'EP'\n",
    "}\n",
    "\n",
    "with open(disturbance_thresholds_path, 'r') as f:\n",
    "    disturbance_thresholds = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72ca8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image(array, title):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    cmap = plt.cm.RdBu\n",
    "\n",
    "    if array.dtype == bool:\n",
    "        # Convert boolean values to 1.0 (True) and -1.0 (False)\n",
    "        image = np.where(array, -1.0, 1.0)\n",
    "    else:\n",
    "        # Map float values to 1.0 (>=0) and -1.0 (<0)\n",
    "        image = np.where(array >= 0, 1.0, -1.0)\n",
    "\n",
    "    plt.imshow(image, cmap=cmap, interpolation='none')\n",
    "    plt.title(title)\n",
    "\n",
    "    for i in range(array.shape[0] + 1):\n",
    "        plt.axhline(i - 0.5, color='black', lw=0.5)\n",
    "        plt.axvline(i - 0.5, color='black', lw=0.5)\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def list_available_parameters(grib_file):\n",
    "    try:\n",
    "        # Open the GRIB file\n",
    "        grbs = pygrib.open(grib_file)\n",
    "\n",
    "        # Initialize a list to store parameter information\n",
    "        parameter_info = []\n",
    "\n",
    "        # Iterate through the GRIB messages and extract parameter information\n",
    "        for grb in grbs:\n",
    "            parameter_name = grb.name\n",
    "            parameter_unit = grb.units\n",
    "            level_type = grb.levelType\n",
    "            level = grb.level\n",
    "            print(grb)\n",
    "            parameter_info.append({\n",
    "                \"Parameter Name\": parameter_name,\n",
    "                \"Unit\": parameter_unit,\n",
    "                \"Level Type\": level_type,\n",
    "                \"Level\": level\n",
    "            })\n",
    "\n",
    "        # Close the GRIB file\n",
    "        grbs.close()\n",
    "\n",
    "        # Print the information for parameters\n",
    "        for info in parameter_info:\n",
    "            print(\"Parameter Name:\", info[\"Parameter Name\"])\n",
    "            print(\"Unit:\", info[\"Unit\"])\n",
    "            print(\"Level Type:\", info[\"Level Type\"])\n",
    "            print(\"Level:\", info[\"Level\"])\n",
    "            print(\"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        traceback.print_exc(limit=None, file=None, chain=True)\n",
    "\n",
    "def convert_to_signed_lon(lon):\n",
    "    # Convert longitudes from 0-360 range to -180 to +180 range\n",
    "    return (lon + 180) % 360 - 180\n",
    "\n",
    "# this is in a number of cells radius from the center (so a neighborhood size of 1 would be 3x3)\n",
    "def calculate_neighborhood_size(degree_radius, grid_resolution):\n",
    "    # Calculate the radius in grid points\n",
    "    radius_in_grid_points = int(degree_radius / grid_resolution)\n",
    "    return radius_in_grid_points\n",
    "\n",
    "def array_indices_to_lat_lon(x, y, lats, lons):\n",
    "    lat = lats[x, y]\n",
    "    lon = lons[x, y]\n",
    "    signed_lon = convert_to_signed_lon(lon)\n",
    "    return lat, signed_lon\n",
    "\n",
    "# print candidates\n",
    "def print_candidates(mslp_minima_list, lats = None, lons = None, meet_all_disturbance_thresholds = False):\n",
    "    n = 0\n",
    "    for candidate in mslp_minima_list:\n",
    "        if meet_all_disturbance_thresholds:\n",
    "            if not candidate['criteria']['all']:\n",
    "                continue\n",
    "\n",
    "        basin_str = \"\"\n",
    "        if 'basin' in candidate:\n",
    "            basin = candidate['basin']\n",
    "            basin_str += f'{basin} Basin, '\n",
    "        \n",
    "        n += 1\n",
    "        mslp_value = candidate[\"mslp_value\"]\n",
    "        \n",
    "        if lats is not None and lons is not None:\n",
    "            x = candidate[\"x_value\"]\n",
    "            y = candidate[\"y_value\"]\n",
    "            lat, lon = array_indices_to_lat_lon(x, y, lats, lons)\n",
    "        else:\n",
    "            lat = candidate['lat']\n",
    "            lon = candidate['lon']\n",
    "\n",
    "        formatted_mslp = f\"{mslp_value:.1f}\".rjust(6, ' ')\n",
    "        rv_str = \"\"\n",
    "        if 'rv850max'in candidate:\n",
    "            rv_str = \", 850 RV MAX (*10^-5 1/s): \"\n",
    "            rv_value = candidate['rv850max'] * np.power(10.0,5)\n",
    "            formatted_rv = f\"{rv_value:2.2f}\".rjust(5, ' ')\n",
    "            rv_str += formatted_rv\n",
    "        \n",
    "        thickness_str = \"\"\n",
    "        if 'gp250_850_thickness' in candidate:\n",
    "            thickness_str = \", 250-850 hPa Thickness (m): \"\n",
    "            thickness_value = candidate['gp250_850_thickness']\n",
    "            formatted_thickness = f\"{thickness_value:2.2f}\".rjust(6, ' ')\n",
    "            thickness_str += formatted_thickness\n",
    "        \n",
    "        vmax_str = \"\"\n",
    "        if 'vmax925' in candidate:\n",
    "            vmax_str = \", 925 hPa WS MAX (m/s): \"\n",
    "            vmax_value = candidate['vmax925']\n",
    "            formatted_vmax = f\"{vmax_value:3.2f}\".rjust(6, ' ')\n",
    "            vmax_str += formatted_vmax\n",
    "        \n",
    "        print(f\"#{n: >2}, {basin_str}Latitude (deg:): {lat: >6.1f}, Longitude (deg): {lon: >6.1f}, MSLP (hPa): {formatted_mslp}{rv_str}{thickness_str}{vmax_str}\")\n",
    "\n",
    "        if debug_isobar_images:\n",
    "            create_image(candidate['neighborhood'], 'Neighborhood')\n",
    "            create_image(candidate['visited'], 'Visited')\n",
    "        \n",
    "# this function is for checking find_mslp_minima_with_closed_isobars\n",
    "def find_mslp_minima(mslp_data, minima_neighborhood_size=1):\n",
    "    try:\n",
    "        # Lists to store MSLP minima, latitudes, and longitudes\n",
    "        candidates = []\n",
    "\n",
    "        # Loop through each grid point\n",
    "        for x in range(minima_neighborhood_size, mslp_data.shape[0] - minima_neighborhood_size):\n",
    "            for y in range(minima_neighborhood_size, mslp_data.shape[1] - minima_neighborhood_size):\n",
    "                mslp_value = mslp_data[x, y]  # MSLP value at the current point\n",
    "                neighborhood = mslp_data[x - minima_neighborhood_size:x + minima_neighborhood_size + 1,\n",
    "                                         y - minima_neighborhood_size:y + minima_neighborhood_size + 1]\n",
    "\n",
    "                # Check if the MSLP value is the minimum within the neighborhood\n",
    "                if mslp_value == neighborhood.min():\n",
    "                    candidate = {\n",
    "                        \"mslp_value\": mslp_value,\n",
    "                        \"x_value\": x,\n",
    "                        \"y_value\": y\n",
    "                    }\n",
    "                    candidates.append(candidate)\n",
    "\n",
    "\n",
    "        return candidates\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        traceback.print_exc(limit=None, file=None, chain=True)\n",
    "        return [], [], []\n",
    "\n",
    "# minima_neighborhood_size set to 1 finds the smallest area that could be called a relative minima in MSLP\n",
    "# this can create many duplicates for the same cyclone\n",
    "# [1] uses a 3 degree buffer over space and time to group together these disturbances as a cyclone:\n",
    "# Quoting [1]; \"a 3° buffer around the position at forecast hour 12. Note that the position at forecast hour 18 is on or within the 3° buffer. Thus, these two points are considered to be the same TC. A new buffer is then drawn around the location at forecast hour 18 (green box), and a search is done for any positions on or within the buffer at forecast hour 24. This process is repeated until no points are found on or within the buffer.\"\n",
    "def find_mslp_minima_with_closed_isobars(mslp_data, grid_resolution, isobar_threshold=2.0, isobar_search_radius_degrees = 5, minima_neighborhood_size = 1):\n",
    "    isobar_neighborhood_size = calculate_neighborhood_size(isobar_search_radius_degrees, grid_resolution)\n",
    "    #print('isobar neighborsize', isobar_neighborhood_size)\n",
    "    def dfs(x, y):\n",
    "        nonlocal visited\n",
    "        stack = [(x, y)]\n",
    "\n",
    "        while stack:\n",
    "            x, y = stack.pop()\n",
    "            visited[x][y] = True\n",
    "\n",
    "            # Check N, S, E, W neighbors\n",
    "            neighbors = [(x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1)]\n",
    "\n",
    "            for nx, ny in neighbors:\n",
    "                if 0 <= nx < isobar_neighborhood_size * 2 + 1 and 0 <= ny < isobar_neighborhood_size * 2 + 1:\n",
    "                    if not visited[nx][ny]:\n",
    "                        if nx == 0 or ny == 0 or nx == isobar_neighborhood_size * 2 or ny == isobar_neighborhood_size * 2:\n",
    "                            return False\n",
    "                        if neighborhood_modified[nx][ny] < 0:\n",
    "                            stack.append((nx, ny))\n",
    "        return True\n",
    "\n",
    "    try:\n",
    "        # List to store MSLP minima as dictionaries\n",
    "        mslp_minima_list = []\n",
    "\n",
    "        # Create a list of candidates for MSLP minima\n",
    "        candidates = []\n",
    "\n",
    "        # Loop through each grid point\n",
    "        for x in range(mslp_data.shape[0]):\n",
    "            for y in range(mslp_data.shape[1]):\n",
    "                mslp_value = mslp_data[x, y]  # MSLP value at the current point\n",
    "                \n",
    "                x_min = x - minima_neighborhood_size\n",
    "                x_max = x + minima_neighborhood_size + 1\n",
    "                y_min = y - minima_neighborhood_size\n",
    "                y_max = y + minima_neighborhood_size + 1\n",
    "\n",
    "                in_bounds = ((x_min >= 0) and\n",
    "                    (x_max <= mslp_data.shape[0]) and\n",
    "                    (y_min >= 0) and\n",
    "                    (y_max <= mslp_data.shape[1]))\n",
    "\n",
    "                if in_bounds:\n",
    "                    # the normal case (not edges of array)\n",
    "                    neighborhood = mslp_data[x_min:x_max, y_min:y_max]\n",
    "                else:\n",
    "                    # handle indices at the boundaries\n",
    "                    neighborhood = extract_2d_neighborhood(mslp_data, (x, y), minima_neighborhood_size)\n",
    "                \n",
    "                # Check if the MSLP value is the minimum within the neighborhood\n",
    "                if mslp_value == neighborhood.min():\n",
    "                    candidates.append((x, y, mslp_value))\n",
    "\n",
    "        # Loop through the candidates to find isobars\n",
    "        for x, y, minima_value in candidates:\n",
    "            # Create a modified neighborhood for isobar calculation\n",
    "            \n",
    "            x_min = x - isobar_neighborhood_size\n",
    "            x_max = x + isobar_neighborhood_size + 1\n",
    "            y_min = y - isobar_neighborhood_size\n",
    "            y_max = y + isobar_neighborhood_size + 1\n",
    "            \n",
    "            in_bounds = ((x_min >= 0) and\n",
    "                (x_max <= mslp_data.shape[0]) and\n",
    "                (y_min >= 0) and\n",
    "                (y_max <= mslp_data.shape[1]))\n",
    "\n",
    "            if in_bounds:\n",
    "                # the normal case (not edges of array)\n",
    "                neighborhood = mslp_data[x_min:x_max, y_min:y_max]\n",
    "            else:\n",
    "                # handle indices at the boundaries\n",
    "                neighborhood = extract_2d_neighborhood(mslp_data, (x, y), isobar_neighborhood_size)\n",
    "\n",
    "            neighborhood_modified = neighborhood - minima_value - isobar_threshold\n",
    "\n",
    "            # Initialize visited array for DFS\n",
    "            visited = np.zeros_like(neighborhood_modified, dtype=bool)\n",
    "\n",
    "            # Flag to track if a closed path is found\n",
    "            path_found = dfs(isobar_neighborhood_size, isobar_neighborhood_size)\n",
    "\n",
    "            if path_found:\n",
    "                # Store MSLP minima data as a dictionary\n",
    "                if debug_isobar_images:\n",
    "                    candidate = {\n",
    "                        \"mslp_value\": minima_value,\n",
    "                        \"x_value\": x,\n",
    "                        \"y_value\": y,\n",
    "                        \"neighborhood\": copy.deepcopy(neighborhood_modified),\n",
    "                        \"visited\": copy.deepcopy(visited)\n",
    "                    }\n",
    "                else:\n",
    "                    candidate = {\n",
    "                        \"mslp_value\": minima_value,\n",
    "                        \"x_value\": x,\n",
    "                        \"y_value\": y\n",
    "                    }\n",
    "                mslp_minima_list.append(candidate)\n",
    "\n",
    "\n",
    "        return mslp_minima_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        traceback.print_exc(limit=None, file=None, chain=True)\n",
    "        return []\n",
    "\n",
    "# calculate vorticity (accounting for projection distortion) using metpy (uses finite differences method)\n",
    "# returns vorticity using an ellipsoid based on WGS84\n",
    "def calculate_vorticity(u_wind_850, v_wind_850, lats, lons):\n",
    "    # Calculate grid spacing distances (these will be the dx and dy values used for calculating vorticity)\n",
    "    ellipsoid = pyproj.Geod(ellps=\"WGS84\")\n",
    "    dx, dy = mpcalc.lat_lon_grid_deltas(lons * units.degrees, lats * units.degrees, geod=ellipsoid)\n",
    "\n",
    "    # Convert wind components to units\n",
    "    u_wind_850_with_units = units.Quantity(u_wind_850, 'm/s')\n",
    "    v_wind_850_with_units = units.Quantity(v_wind_850, 'm/s')\n",
    "\n",
    "    # Calculate relative vorticity (use WGS84)\n",
    "    vort_850 = np.array(mpcalc.vorticity(u_wind_850_with_units, v_wind_850_with_units, dx=dx, dy=dy))\n",
    "    \n",
    "    # return as a masked array (this will hide NaNs: needed for getting the correct max and saving the calculation)\n",
    "    return np.ma.masked_invalid(vort_850)\n",
    "\n",
    "# Function to find RV maximums in neighborhoods for a list of candidates\n",
    "def find_rv_maximums_in_neighborhoods(mslp_minima_list, rv, grid_resolution, relative_vorticity_radius_degrees = 2):\n",
    "    neighborhood_size = calculate_neighborhood_size(relative_vorticity_radius_degrees, grid_resolution)\n",
    "    updated_mslp_minima_list = []\n",
    "\n",
    "    for candidate in mslp_minima_list:\n",
    "        x, y, _ = candidate[\"x_value\"], candidate[\"y_value\"], candidate[\"mslp_value\"]\n",
    "\n",
    "        # Extract the neighborhood for the current candidate\n",
    "        x_min = x - neighborhood_size\n",
    "        x_max = x + neighborhood_size + 1\n",
    "        y_min = y - neighborhood_size\n",
    "        y_max = y + neighborhood_size + 1\n",
    "\n",
    "        in_bounds = ((x_min >= 0) and\n",
    "            (x_max <= rv.shape[0]) and\n",
    "            (y_min >= 0) and\n",
    "            (y_max <= rv.shape[1]))\n",
    "\n",
    "        if in_bounds:\n",
    "            # the normal case (not edges of array)\n",
    "            neighborhood = rv[x_min:x_max, y_min:y_max]\n",
    "        else:\n",
    "            # handle indices at the boundaries\n",
    "            neighborhood = extract_2d_neighborhood(rv, (x, y), neighborhood_size)\n",
    "\n",
    "        # Find the maximum RV value within the neighborhood\n",
    "        rv_max = neighborhood.max()\n",
    "\n",
    "        # Update a copy of the candidate's dictionary with rv maximum value\n",
    "        updated_candidate = copy.deepcopy(candidate)\n",
    "        updated_candidate[\"rv850max\"] = rv_max\n",
    "\n",
    "        # Add the updated candidate to the list\n",
    "        updated_mslp_minima_list.append(updated_candidate)\n",
    "\n",
    "    return updated_mslp_minima_list\n",
    "    \n",
    "# calculate relative max thickness for 250hPa - 850hPa for a list of candidates\n",
    "def find_gp_250_850_max_thickness(mslp_minima_list, geopotential_250, geopotential_850, grid_resolution, degrees_radius=2):\n",
    "    # Calculate the neighborhood size based on degrees_radius and grid_resolution\n",
    "    neighborhood_size = calculate_neighborhood_size(degrees_radius, grid_resolution)\n",
    "\n",
    "    updated_mslp_minima_list = []\n",
    "    \n",
    "    # Iterate over the list of candidates\n",
    "    for candidate in mslp_minima_list:\n",
    "        # Extract the x and y indices of the candidate\n",
    "        x, y = candidate['x_value'], candidate['y_value']\n",
    "\n",
    "        # Extract the neighborhoods for 250 hPa and 850 hPa\n",
    "        x_min = x - neighborhood_size\n",
    "        x_max = x + neighborhood_size + 1\n",
    "        y_min = y - neighborhood_size\n",
    "        y_max = y + neighborhood_size + 1\n",
    "\n",
    "        in_bounds = ((x_min >= 0) and\n",
    "            (x_max <= geopotential_250.shape[0]) and\n",
    "            (y_min >= 0) and\n",
    "            (y_max <= geopotential_250.shape[1]))\n",
    "\n",
    "        if in_bounds:\n",
    "            # the normal case (not edges of array)\n",
    "            neighborhood_250 = geopotential_250[x_min:x_max, y_min:y_max]\n",
    "            neighborhood_850 = geopotential_850[x_min:x_max, y_min:y_max]\n",
    "        else:\n",
    "            # handle indices at the boundaries\n",
    "            neighborhood_250 = extract_2d_neighborhood(geopotential_250, (x, y), neighborhood_size)\n",
    "            neighborhood_850 = extract_2d_neighborhood(geopotential_850, (x, y), neighborhood_size)\n",
    "\n",
    "        # Calculate the 250–850-hPa thickness for each cell in the neighborhood\n",
    "        thickness = neighborhood_250 - neighborhood_850\n",
    "\n",
    "        # Find the maximum thickness value in the neighborhood\n",
    "        max_thickness = thickness.max()\n",
    "\n",
    "        # Update a copy of the candidate's dictionary with the maximum thickness value\n",
    "        updated_candidate = copy.deepcopy(candidate)\n",
    "        updated_candidate['gp250_850_thickness'] = max_thickness\n",
    "        \n",
    "        # Add the updated candidate to the list\n",
    "        updated_mslp_minima_list.append(updated_candidate)\n",
    "\n",
    "    return updated_mslp_minima_list\n",
    "\n",
    "# find max wind at 925 hPa for a list of candidates\n",
    "def find_max_wind_925(mslp_minima_list, u_wind_925, v_wind_925, grid_resolution, degrees_radius=5):\n",
    "    # Calculate the neighborhood size based on radius_degrees and grid_resolution for wind\n",
    "    neighborhood_size = calculate_neighborhood_size(degrees_radius, grid_resolution)\n",
    "\n",
    "    updated_mslp_minima_list = []\n",
    "\n",
    "    # Iterate over the list of candidates\n",
    "    for candidate in mslp_minima_list:\n",
    "        # Extract the neighborhoods for u-wind and v-wind at 925 hPa\n",
    "\n",
    "        # Extract the x and y indices of the candidate\n",
    "        x = candidate['x_value']\n",
    "        y = candidate['y_value']\n",
    "        \n",
    "        x_min = x - neighborhood_size\n",
    "        x_max = x + neighborhood_size + 1\n",
    "        y_min = y - neighborhood_size\n",
    "        y_max = y + neighborhood_size + 1\n",
    "\n",
    "        in_bounds = ((x_min >= 0) and\n",
    "            (x_max <= u_wind_925.shape[0]) and\n",
    "            (y_min >= 0) and\n",
    "            (y_max <= u_wind_925.shape[1]))\n",
    "\n",
    "        if in_bounds:\n",
    "            # the normal case (not edges of array)\n",
    "            neighborhood_u_wind = u_wind_925[x_min:x_max, y_min:y_max]\n",
    "            neighborhood_v_wind = v_wind_925[x_min:x_max, y_min:y_max]\n",
    "        else:\n",
    "            # handle indices at the boundaries\n",
    "            neighborhood_u_wind = extract_2d_neighborhood(u_wind_925, (x, y), neighborhood_size)\n",
    "            neighborhood_v_wind = extract_2d_neighborhood(v_wind_925, (x, y), neighborhood_size)\n",
    "\n",
    "        # Calculate wind speed in the neighborhood\n",
    "        wind_speed = np.sqrt(neighborhood_u_wind ** 2 + neighborhood_v_wind ** 2)\n",
    "\n",
    "        # Find the maximum wind speed value in the neighborhood\n",
    "        max_wind_speed = wind_speed.max()\n",
    "\n",
    "        # Update a copy of the candidate's dictionary with the maximum wind speed value\n",
    "        updated_candidate = copy.deepcopy(candidate)\n",
    "        updated_candidate['vmax925'] = max_wind_speed\n",
    "        \n",
    "        # Add the updated candidate to the list\n",
    "        updated_mslp_minima_list.append(updated_candidate)\n",
    "\n",
    "    return updated_mslp_minima_list\n",
    "\n",
    "# add basin name, and also removes candidates that aren't in one of the basins\n",
    "# add lat,lon also\n",
    "def add_basin_name(mslp_minima_list, lats, lons):\n",
    "    updated_mslp_minima_list = []\n",
    "\n",
    "    for candidate in mslp_minima_list:\n",
    "        x = candidate[\"x_value\"]\n",
    "        y = candidate[\"y_value\"]\n",
    "\n",
    "        lat, lon = array_indices_to_lat_lon(x, y, lats, lons)\n",
    "        basin_name = get_basin_name_from_lat_lon(lat, lon)\n",
    "        \n",
    "        # remove candidate if not in a basin we are considering\n",
    "        if not basin_name:\n",
    "            continue\n",
    "        \n",
    "        # Update a copy of the candidate's dictionary with rv maximum value\n",
    "        updated_candidate = copy.deepcopy(candidate)\n",
    "        updated_candidate['basin'] = basin_name\n",
    "        updated_candidate['lat'] = lat\n",
    "        updated_candidate['lon'] = lon\n",
    "        \n",
    "        updated_mslp_minima_list.append(updated_candidate)\n",
    "\n",
    "    return updated_mslp_minima_list\n",
    "\n",
    "# Function to calculate the booleans on disturbance thresholds are met or not for each criteria and for all\n",
    "# Must calculate and update with the basin classification first\n",
    "def calc_disturbance_threshold_booleans(mslp_minima_list, model_name):\n",
    "    updated_mslp_minima_list = []\n",
    "\n",
    "    for candidate in mslp_minima_list:\n",
    "        # Update a copy of the candidate's dictionary with rv maximum value\n",
    "        updated_candidate = copy.deepcopy(candidate)\n",
    "        all_met = True\n",
    "        \n",
    "        basin_name = candidate[\"basin\"]\n",
    "        lat = candidate[\"lat\"]\n",
    "        # expect positive vorticity for northern hemisphere, negative for southern hemisphere\n",
    "        if lat >= 0:\n",
    "            relative_vorticity_sign = 1\n",
    "        else:\n",
    "            relative_vorticity_sign = -1\n",
    "        \n",
    "        for criteria_abbrev, criteria_value in disturbance_thresholds[model_name][basin_name].items():\n",
    "            criteria_name = disturbance_criteria_names_map[criteria_abbrev]\n",
    "            if criteria_name == 'rv850max':\n",
    "                # thresholds in the JSON for RV are scaled by 10^5\n",
    "                criteria_value *= pow(10, -5)\n",
    "            criteria_bool = False\n",
    "            # also, flip the sign for southern hemisphere\n",
    "            if updated_candidate[criteria_name] * relative_vorticity_sign >= criteria_value:\n",
    "                criteria_bool = True\n",
    "            if 'criteria' not in updated_candidate:\n",
    "                updated_candidate['criteria'] = {}\n",
    "            updated_candidate['criteria'][criteria_name] = criteria_bool\n",
    "            all_met = (all_met and criteria_bool)\n",
    "\n",
    "        updated_candidate['criteria']['all'] = all_met\n",
    "        # Add the updated candidate to the list\n",
    "        updated_mslp_minima_list.append(updated_candidate)\n",
    "\n",
    "    return updated_mslp_minima_list\n",
    "\n",
    "# returns the basin name from lat, lon if in a basin that is covered by the thresholds, otherwise returns None\n",
    "def get_basin_name_from_lat_lon(lat, lon):\n",
    "    # Create a Point geometry for the latitude and longitude\n",
    "    point = Point(lon, lat)\n",
    "\n",
    "    # Check if the point is within any of the polygons\n",
    "    result = gdf[gdf.geometry.covers(point)]\n",
    "    if not result.empty:\n",
    "        shape_basin_name = result['basin_name'].iloc[0]\n",
    "        # this is used for thresholds so return the threshold name\n",
    "        return shape_basin_names_to_threshold_names_map[shape_basin_name]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# use u_wind_850 grib as reference and modify message to store vorticity\n",
    "def save_vorticity_to_grib(u_wind_850_grib_file_path = None, grib_dest_file_path = None, relative_vorticity = None):\n",
    "    if u_wind_850_grib_file_path is None or grib_dest_file_path is None or relative_vorticity is None:\n",
    "        return\n",
    "    \n",
    "    print(\"open wind\")\n",
    "    grbs = pygrib.open(u_wind_850_grib_file_path)\n",
    "    modified_grbs = []\n",
    "    # Define the updated attributes for relative vorticity\n",
    "    new_param_id = 138\n",
    "    new_short_name = 'vo'\n",
    "\n",
    "    for grb in grbs:\n",
    "        # Modify parameter information\n",
    "        grb.shortName = new_short_name\n",
    "        grb.paramId = new_param_id\n",
    "        # Replace values\n",
    "        print(\"replaced names/id. replacing values\")\n",
    "        grb.values = relative_vorticity\n",
    "        print(\"replaced values\")\n",
    "        modified_grbs.append(grb)\n",
    "\n",
    "    print(\"open file for write\")\n",
    "    # Create a new GRIB file with modified data\n",
    "    with open(grib_dest_file_path, 'wb') as output_file:\n",
    "        for modified_grb in modified_grbs:\n",
    "            print(\"write file\")\n",
    "            output_file.write(modified_grb.tostring())\n",
    "    print(\"done save\")\n",
    "\n",
    "# filter out candidates not meeting criteria\n",
    "def get_disturbance_candidates_from_split_gribs(grib_files, model_name):\n",
    "    # grid_resolution in degrees. MSLP is converted hPa, rest are converted to metric. Relative vorticity (1/s) is not scaled as threshold (not * 10^5)\n",
    "    time_start = time.time()\n",
    "    grid_resolution, lats, lons, mslp, u_wind_925, v_wind_925, u_wind_850, v_wind_850, geopotential_250, geopotential_850, relative_vorticity_850, u_wind_850_grib_file_path = load_and_extract_split_grib_data(grib_files, model_name)\n",
    "    time_end = time.time()\n",
    "    print(f'load_and_extract_split_grib_data() time (seconds): {time_end - time_start:.1f}')\n",
    "    \n",
    "    # check if an error was caught\n",
    "    if lats is None:\n",
    "        return None\n",
    "    \n",
    "    time_start = time.time()\n",
    "    mslp_minima_list_with_closed_isobars = find_mslp_minima_with_closed_isobars(mslp, grid_resolution['mslp'])\n",
    "    time_end = time.time()\n",
    "    print(f'find_mslp_minima_with_closed_isobars() time (seconds): {time_end - time_start:.1f}')\n",
    "    \n",
    "    # if vorticity is missing, calculate relative vorticity for the entire data set first\n",
    "    if relative_vorticity_850 is None:\n",
    "        time_start = time.time()\n",
    "        # this may issue warnings for divide by 0 for vorticity calculations\n",
    "        print(\"Calculating Relative vorticity for 850 hPa\")\n",
    "        rv_850 = calculate_vorticity(u_wind_850, v_wind_850, lats, lons)\n",
    "        time_end = time.time()\n",
    "        print(f'calculate_vorticity() time (seconds): {time_end - time_start:.1f}')\n",
    "        print(\"Finished calculating vorticity\")\n",
    "        # save the vorticity calculated to grib?\n",
    "        if debug_save_vorticity:\n",
    "            grib_dir = os.path.dirname(u_wind_850_grib_file_path)\n",
    "            grib_dest_file_path = os.path.join(grib_dir, 'calculated_relative_vorticity.grib')\n",
    "            print(\"Save vorticity...\")\n",
    "            save_vorticity_to_grib(u_wind_850_grib_file_path = u_wind_850_grib_file_path, grib_dest_file_path = grib_dest_file_path, relative_vorticity = rv_850)\n",
    "    else:\n",
    "        rv_850 = relative_vorticity_850\n",
    "\n",
    "    # calculate relative vorticity maximum for each candidate\n",
    "    time_start = time.time()\n",
    "    mslp_minima_list_with_closed_isobars = find_rv_maximums_in_neighborhoods(mslp_minima_list_with_closed_isobars, rv_850, grid_resolution['gh250'])\n",
    "    time_end = time.time()\n",
    "    print(f'find_rv_maximums_in_neighborhoods() time (seconds): {time_end - time_start:.1f}')\n",
    "    \n",
    "    time_start = time.time()\n",
    "    # Find the maximum relative thickness (250 - 850 hPa) for each candidate\n",
    "    mslp_minima_list_with_closed_isobars = find_gp_250_850_max_thickness(mslp_minima_list_with_closed_isobars, geopotential_250, geopotential_850, grid_resolution['gh250'])\n",
    "    time_end = time.time()\n",
    "    print(f'find_gp_250_850_max_thickness() time (seconds): {time_end - time_start:.1f}')\n",
    "\n",
    "    time_start = time.time()\n",
    "    # find the maximum 925 hPa wind speed\n",
    "    mslp_minima_list_with_closed_isobars = find_max_wind_925(mslp_minima_list_with_closed_isobars, u_wind_925, v_wind_925, grid_resolution['uwind925'])\n",
    "    time_end = time.time()\n",
    "    print(f'find_max_wind_925() time (seconds): {time_end - time_start:.1f}')\n",
    "    \n",
    "    time_start = time.time()\n",
    "    # get lat/lon and basin name (exclude ones not in a basin we cover)\n",
    "    mslp_minima_list_in_basins = add_basin_name(mslp_minima_list_with_closed_isobars, lats, lons)\n",
    "    time_end = time.time()\n",
    "    print(f'add_basin_name() time (seconds): {time_end - time_start:.1f}')\n",
    "    \n",
    "    time_start = time.time()\n",
    "    mslp_minima_list_with_disturbance_threshold_booleans = calc_disturbance_threshold_booleans(mslp_minima_list_in_basins, model_name)\n",
    "    time_end = time.time()\n",
    "    print(f'calc_disturbance_threshold_booleans() time (seconds): {time_end - time_start:.1f}')\n",
    "    # print_candidates(mslp_minima_list_with_disturbance_threshold_booleans, lats, lons, meet_all_disturbance_thresholds = True)\n",
    "\n",
    "    time_start = time.time()\n",
    "    # exclude disturbances not meeting all criteria\n",
    "    updated_mslp_minima_list = []\n",
    "    # Iterate over the list of candidates\n",
    "    for candidate in mslp_minima_list_with_disturbance_threshold_booleans:\n",
    "        # exclude candidates not meeting all criteria\n",
    "        if not candidate['criteria']['all']:\n",
    "            continue\n",
    "\n",
    "        # Update a copy of the candidate's dictionary with LAT, LON\n",
    "        updated_candidate = copy.deepcopy(candidate)\n",
    "        \n",
    "        # Add the updated candidate to the list\n",
    "        updated_mslp_minima_list.append(updated_candidate)\n",
    "\n",
    "    time_end = time.time()\n",
    "    print(f'Remove candidates not meeting all criteria, time (seconds): {time_end - time_start:.1f}')\n",
    "    print('\\n')\n",
    "    return updated_mslp_minima_list\n",
    "\n",
    "def load_and_extract_split_grib_data(grib_files, model_name):\n",
    "    try:\n",
    "        # Initialize variables for relevant parameters\n",
    "        mslp = None\n",
    "        u_wind_925 = None\n",
    "        v_wind_925 = None\n",
    "        u_wind_850 = None\n",
    "        v_wind_850 = None\n",
    "        geopotential_250 = None\n",
    "        geopotential_850 = None\n",
    "        relative_vorticity_850 = None\n",
    "        \n",
    "        mslp_units = None\n",
    "        wind_925_units = None\n",
    "        wind_850_units = None\n",
    "        \n",
    "        mslp_lats = None\n",
    "        mslp_lons = None\n",
    "        u_wind_925_lats = None\n",
    "        u_wind_925_lons = None\n",
    "        v_wind_925_lats = None\n",
    "        v_wind_925_lons = None\n",
    "        u_wind_850_lats = None\n",
    "        u_wind_850_lons = None\n",
    "        v_wind_850_lats = None\n",
    "        v_wind_850_lons = None\n",
    "        geopotential_250_lats = None\n",
    "        geopotential_250_lons = None\n",
    "        geopotential_850_lats = None\n",
    "        geopotential_850_lons = None\n",
    "        relative_vorticity_850_lats = None\n",
    "        relative_vorticity_850_lons = None\n",
    "        \n",
    "        # only used for reference to optionally store calculated relative vorticity\n",
    "        u_wind_850_grib_file_path = None\n",
    "        \n",
    "        grid_resolution = {}\n",
    "\n",
    "        for grib_file in grib_files:\n",
    "            # Open the GRIB file\n",
    "            grbs = pygrib.open(grib_file)\n",
    "            # Extract relevant parameters (modify the parameter names and levels accordingly)\n",
    "            for grb in grbs:\n",
    "                if grb.level == 0 and grb.name in ['Pressure reduced to MSL', 'Mean sea level pressure']:\n",
    "                    mslp = grb.values\n",
    "                    mslp_units = grb.units\n",
    "                    mslp_lats, mslp_lons = grb.latlons()\n",
    "                    grid_resolution['mslp'] = grb['iDirectionIncrementInDegrees']\n",
    "                elif grb.name == 'U component of wind' and grb.level == 925:\n",
    "                    u_wind_925 = grb.values\n",
    "                    wind_925_units = grb.units\n",
    "                    u_wind_925_lats, u_wind_925_lons = grb.latlons()\n",
    "                    grid_resolution['uwind925'] = grb['iDirectionIncrementInDegrees']\n",
    "                elif grb.name == 'V component of wind' and grb.level == 925:\n",
    "                    v_wind_925 = grb.values\n",
    "                    v_wind_925_lats, v_wind_925_lons = grb.latlons()\n",
    "                    grid_resolution['vwind925'] = grb['iDirectionIncrementInDegrees']\n",
    "                elif grb.name == 'U component of wind' and grb.level == 850:\n",
    "                    u_wind_850 = grb.values\n",
    "                    wind_850_units = grb.units\n",
    "                    u_wind_850_lats, u_wind_850_lons = grb.latlons()\n",
    "                    u_wind_850_grib_file_path = grib_file\n",
    "                    grid_resolution['uwind850'] = grb['iDirectionIncrementInDegrees']\n",
    "                elif grb.name == 'V component of wind' and grb.level == 850:\n",
    "                    v_wind_850 = grb.values\n",
    "                    v_wind_850_lats, v_wind_850_lons = grb.latlons()\n",
    "                    grid_resolution['vwind850'] = grb['iDirectionIncrementInDegrees']\n",
    "                elif grb.name == 'Geopotential Height' and grb.level == 250:\n",
    "                    geopotential_250 = grb.values\n",
    "                    geopotential_250_lats, geopotential_250_lons = grb.latlons()\n",
    "                    grid_resolution['gh250'] = grb['iDirectionIncrementInDegrees']\n",
    "                elif grb.name == 'Geopotential Height' and grb.level == 850:\n",
    "                    geopotential_850 = grb.values\n",
    "                    geopotential_850_lats, geopotential_850_lons = grb.latlons()\n",
    "                    grid_resolution['gh850'] = grb['iDirectionIncrementInDegrees']\n",
    "                elif grb.name == 'Vorticity (relative)' and grb.level == 850:\n",
    "                    relative_vorticity_850 = grb.values\n",
    "                    relative_vorticity_850_lats, relative_vorticity_850_lons = grb.latlons()\n",
    "                    grid_resolution['rv850'] = grb['iDirectionIncrementInDegrees']\n",
    "\n",
    "            # Close the GRIB file\n",
    "            grbs.close()\n",
    "\n",
    "        # Check if units are not in hPa and convert if necessary\n",
    "        if mslp_units != \"hPa\":\n",
    "            #print(f\"Converting MSLP units from {mslp_units} to hPa\")\n",
    "            if mslp_units == \"Pa\":\n",
    "                # Convert from Pa to hPa\n",
    "                mslp *= 0.01\n",
    "                mslp_units = \"hPa\"\n",
    "            else:\n",
    "                print(\"Warning: Units of MSLP are not in Pa or hPa. Please verify the units for accurate results.\")\n",
    "\n",
    "        # Check if units are not in m/s for 925 hPa wind components and convert if necessary\n",
    "        if not (re.search(r\"(m/s|m s\\*\\*-1)\", wind_925_units)):\n",
    "            print(f\"Converting 925 hPa wind components units from {wind_925_units} to m/s\")\n",
    "            if re.search(r\"knots|knot\", wind_925_units, re.I):\n",
    "                # Convert from knots to m/s (1 knot ≈ 0.514444 m/s)\n",
    "                u_wind_925 *= 0.514444\n",
    "                v_wind_925 *= 0.514444\n",
    "                wind_925_units = \"m/s\"\n",
    "            else:\n",
    "                print(\"Warning: Units of 925 hPa wind components are not in knots, m/s, or m s**-1. Please verify the units for accurate results.\")\n",
    "                \n",
    "        # Check if units are not in m/s for 925 hPa wind components and convert if necessary\n",
    "        if wind_850_units and not (re.search(r\"(m/s|m s\\*\\*-1)\", wind_850_units)):\n",
    "            print(f\"Converting 850 hPa wind components units from {wind_850_units} to m/s\")\n",
    "            if re.search(r\"knots|knot\", wind_925_units, re.I):\n",
    "                # Convert from knots to m/s (1 knot ≈ 0.514444 m/s)\n",
    "                u_wind_850 *= 0.514444\n",
    "                v_wind_850 *= 0.514444\n",
    "                wind_850_units = \"m/s\"\n",
    "            else:\n",
    "                print(\"Warning: Units of 925 hPa wind components are not in knots, m/s, or m s**-1. Please verify the units for accurate results.\")\n",
    "        \n",
    "        # make sure shapes are all the same\n",
    "        shapes = [x.shape for x in\n",
    "            [\n",
    "                mslp_lats, mslp_lons,\n",
    "                u_wind_925_lats, u_wind_925_lons,\n",
    "                v_wind_925_lats, v_wind_925_lons,\n",
    "                u_wind_850_lats, u_wind_850_lons,\n",
    "                v_wind_850_lats, v_wind_850_lons,\n",
    "                geopotential_250_lats, geopotential_250_lons,\n",
    "                geopotential_850_lats, geopotential_850_lons,\n",
    "                relative_vorticity_850_lats, relative_vorticity_850_lons\n",
    "\n",
    "            ] if x is not None]\n",
    "\n",
    "        # check to make sure all the same shape\n",
    "        if len(set(shapes)) != 1:\n",
    "            # lats and lons different shapes!\n",
    "            print(f\"Error: getting disturbance candidates: lat,lons different shapes for: {grib_files}\")\n",
    "            return None, None, None, None, None, None, None, None, None, None, None, None\n",
    "        \n",
    "        lats = mslp_lats\n",
    "        lons = mslp_lons\n",
    "        \n",
    "        return grid_resolution, lats, lons, mslp, u_wind_925, v_wind_925, u_wind_850, v_wind_850, geopotential_250, geopotential_850, relative_vorticity_850, u_wind_850_grib_file_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        traceback.print_exc(limit=None, file=None, chain=True)\n",
    "\n",
    "def extract_1d_neighborhood(arr, center_index, neighborhood_size):\n",
    "    num_elements = arr.shape[0]\n",
    "    neighborhood = np.zeros(2 * neighborhood_size + 1, dtype=arr.dtype)\n",
    "\n",
    "    for i in range(-neighborhood_size, neighborhood_size + 1):\n",
    "        index = (center_index + i) % num_elements\n",
    "        neighborhood[i + neighborhood_size] = arr[index]\n",
    "\n",
    "    return neighborhood\n",
    "\n",
    "def extract_2d_neighborhood(arr, center_indices, neighborhood_size):\n",
    "    \"\"\"\n",
    "    Extract a 2D neighborhood around a center index in a 2D array.\n",
    "\n",
    "    Parameters:\n",
    "    - arr: The 2D input array.\n",
    "    - center_indices: A tuple (center_x, center_y) specifying the center indices.\n",
    "    - neighborhood_size: The size of the neighborhood (half on each side of the center).\n",
    "\n",
    "    Returns:\n",
    "    - neighborhood: The extracted 2D neighborhood.\n",
    "    \"\"\"\n",
    "    center_x, center_y = center_indices\n",
    "    x_indices = range(center_x - neighborhood_size, center_x + neighborhood_size + 1)\n",
    "\n",
    "    # Initialize an empty 2D neighborhood\n",
    "    neighborhood = np.empty((2 * neighborhood_size + 1, 2 * neighborhood_size + 1), dtype=arr.dtype)\n",
    "    \n",
    "    num_elements = arr.shape[0]\n",
    "    # Extract the 1D neighborhoods for each row\n",
    "    for i, x in enumerate(x_indices):\n",
    "        index = x % num_elements\n",
    "        neighborhood[i] = extract_1d_neighborhood(arr[index], center_y, neighborhood_size)\n",
    "    \n",
    "    return neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5f66d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fde132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4679c622",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_and_extract_split_grib_data() time (seconds): 0.8\n",
      "find_mslp_minima_with_closed_isobars() time (seconds): 3.2\n",
      "find_rv_maximums_in_neighborhoods() time (seconds): 0.0\n",
      "find_gp_250_850_max_thickness() time (seconds): 0.0\n",
      "find_max_wind_925() time (seconds): 0.0\n",
      "add_basin_name() time (seconds): 0.1\n",
      "calc_disturbance_threshold_booleans() time (seconds): 0.0\n",
      "Remove candidates not meeting all criteria, time (seconds): 0.0\n",
      "# 1, EP Basin, Latitude (deg:):   11.0, Longitude (deg):  -96.5, MSLP (hPa):  996.5, 850 RV MAX (*10^-5 1/s): 39.90, 250-850 hPa Thickness (m): 9592.20, 925 hPa WS MAX (m/s):  40.00\n",
      "# 2, IO Basin, Latitude (deg:):   15.5, Longitude (deg):   53.5, MSLP (hPa):  992.7, 850 RV MAX (*10^-5 1/s): 52.50, 250-850 hPa Thickness (m): 9563.82, 925 hPa WS MAX (m/s):  57.82\n",
      "# 3, IO Basin, Latitude (deg:):   16.0, Longitude (deg):   84.5, MSLP (hPa):  986.1, 850 RV MAX (*10^-5 1/s): 57.70, 250-850 hPa Thickness (m): 9620.64, 925 hPa WS MAX (m/s):  58.63\n",
      "# 4, AL Basin, Latitude (deg:):   33.5, Longitude (deg):  -54.5, MSLP (hPa):  970.1, 850 RV MAX (*10^-5 1/s): 84.50, 250-850 hPa Thickness (m): 9682.10, 925 hPa WS MAX (m/s):  67.37\n",
      "Time taken for code execution (seconds): 4.1\n"
     ]
    }
   ],
   "source": [
    "# Get the current time before executing the code\n",
    "time_start = time.time()\n",
    "\n",
    "grib_files = [\n",
    "    '/home/db/metview/JRPdata/navgem2/US058GMET-GR1mdl.0018_0056_09600F0OF2023101906_0100_002500-000000geop_ht',\n",
    "    '/home/db/metview/JRPdata/navgem2/US058GMET-GR1mdl.0018_0056_09600F0OF2023101906_0100_008500-000000geop_ht',\n",
    "    '/home/db/metview/JRPdata/navgem2/US058GMET-GR1mdl.0018_0056_09600F0OF2023101906_0100_008500-000000rltv_vort',\n",
    "    '/home/db/metview/JRPdata/navgem2/US058GMET-GR1mdl.0018_0056_09600F0OF2023101906_0100_009250-000000wnd_ucmp',\n",
    "    '/home/db/metview/JRPdata/navgem2/US058GMET-GR1mdl.0018_0056_09600F0OF2023101906_0100_009250-000000wnd_vcmp',\n",
    "    '/home/db/metview/JRPdata/navgem2/US058GMET-GR1mdl.0018_0056_09600F0OF2023101906_0102_000000-000000pres_msl',\n",
    "    '/home/db/metview/JRPdata/navgem2/US058GMET-GR1mdl.0018_0056_09600F0OF2023101906_0105_000100-000000wnd_ucmp',\n",
    "    '/home/db/metview/JRPdata/navgem2/US058GMET-GR1mdl.0018_0056_09600F0OF2023101906_0105_000100-000000wnd_vcmp'\n",
    "]\n",
    "\n",
    "model_name = 'NAV'\n",
    "candidates2 = get_disturbance_candidates_from_split_gribs(grib_files, model_name)\n",
    "print_candidates(candidates2)\n",
    "\n",
    "# getting the time taken for executing the code in seconds\n",
    "time_end = time.time()\n",
    "\n",
    "# Printing the time taken for code execution\n",
    "print(f'Time taken for code execution (seconds): {time_end - time_start:.1f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c9fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7975f336",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_and_extract_split_grib_data() time (seconds): 4.1\n",
      "find_mslp_minima_with_closed_isobars() time (seconds): 8.2\n",
      "Calculating Relative vorticity for 850 hPa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/db/.local/lib/python3.9/site-packages/pint/facets/plain/quantity.py:986: RuntimeWarning: invalid value encountered in divide\n",
      "  magnitude = magnitude_op(new_self._magnitude, other._magnitude)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_vorticity() time (seconds): 2.1\n",
      "Finished calculating vorticity\n",
      "find_rv_maximums_in_neighborhoods() time (seconds): 0.0\n",
      "find_gp_250_850_max_thickness() time (seconds): 0.0\n",
      "find_max_wind_925() time (seconds): 0.0\n",
      "add_basin_name() time (seconds): 0.4\n",
      "calc_disturbance_threshold_booleans() time (seconds): 0.0\n",
      "Remove candidates not meeting all criteria, time (seconds): 0.0\n",
      "# 1, EP Basin, Latitude (deg:):   22.8, Longitude (deg): -111.8, MSLP (hPa): 1005.4, 850 RV MAX (*10^-5 1/s): 207.69, 250-850 hPa Thickness (m): 9777.45, 925 hPa WS MAX (m/s):  50.33\n",
      "# 2, EP Basin, Latitude (deg:):   22.8, Longitude (deg): -111.0, MSLP (hPa): 1005.1, 850 RV MAX (*10^-5 1/s): 207.69, 250-850 hPa Thickness (m): 9777.45, 925 hPa WS MAX (m/s):  50.33\n",
      "# 3, EP Basin, Latitude (deg:):   21.8, Longitude (deg): -112.0, MSLP (hPa): 1004.7, 850 RV MAX (*10^-5 1/s): 207.69, 250-850 hPa Thickness (m): 9777.45, 925 hPa WS MAX (m/s):  50.33\n",
      "# 4, EP Basin, Latitude (deg:):   20.8, Longitude (deg): -110.0, MSLP (hPa):  967.9, 850 RV MAX (*10^-5 1/s): 207.69, 250-850 hPa Thickness (m): 9777.45, 925 hPa WS MAX (m/s):  50.33\n",
      "# 5, AL Basin, Latitude (deg:):   15.0, Longitude (deg):  -60.0, MSLP (hPa):  996.7, 850 RV MAX (*10^-5 1/s): 156.07, 250-850 hPa Thickness (m): 9610.18, 925 hPa WS MAX (m/s):  38.06\n",
      "# 6, IO Basin, Latitude (deg:):   10.5, Longitude (deg):   58.8, MSLP (hPa):  990.1, 850 RV MAX (*10^-5 1/s): 158.57, 250-850 hPa Thickness (m): 9623.80, 925 hPa WS MAX (m/s):  39.02\n",
      "# 7, EP Basin, Latitude (deg:):    8.8, Longitude (deg):  -96.2, MSLP (hPa): 1008.2, 850 RV MAX (*10^-5 1/s): 38.98, 250-850 hPa Thickness (m): 9529.18, 925 hPa WS MAX (m/s):  18.13\n",
      "# 8, EP Basin, Latitude (deg:):    6.5, Longitude (deg): -157.0, MSLP (hPa): 1004.3, 850 RV MAX (*10^-5 1/s): 19.80, 250-850 hPa Thickness (m): 9540.76, 925 hPa WS MAX (m/s):  14.45\n",
      "# 9, EP Basin, Latitude (deg:):    6.5, Longitude (deg):  -80.5, MSLP (hPa): 1008.3, 850 RV MAX (*10^-5 1/s): 31.93, 250-850 hPa Thickness (m): 9541.92, 925 hPa WS MAX (m/s):  18.43\n",
      "#10, EP Basin, Latitude (deg:):    6.5, Longitude (deg):  -80.0, MSLP (hPa): 1008.1, 850 RV MAX (*10^-5 1/s): 31.93, 250-850 hPa Thickness (m): 9541.92, 925 hPa WS MAX (m/s):  18.43\n",
      "Time taken for code execution (seconds): 14.8\n"
     ]
    }
   ],
   "source": [
    "# Get the current time before executing the code\n",
    "time_start = time.time()\n",
    "\n",
    "grib_files = [\n",
    "    '/home/db/metview/JRPdata/gfs2/gfs.t00z.pgrb2.0p25.f003_hgt_250_mb.grib2',\n",
    "    '/home/db/metview/JRPdata/gfs2/gfs.t00z.pgrb2.0p25.f003_hgt_850_mb.grib2',\n",
    "    '/home/db/metview/JRPdata/gfs2/gfs.t00z.pgrb2.0p25.f003_prmsl_mean_sea_level.grib2',\n",
    "    '/home/db/metview/JRPdata/gfs2/gfs.t00z.pgrb2.0p25.f003_ugrd_10_m_above_ground.grib2',\n",
    "    '/home/db/metview/JRPdata/gfs2/gfs.t00z.pgrb2.0p25.f003_ugrd_850_mb.grib2',\n",
    "    '/home/db/metview/JRPdata/gfs2/gfs.t00z.pgrb2.0p25.f003_ugrd_925_mb.grib2',\n",
    "    '/home/db/metview/JRPdata/gfs2/gfs.t00z.pgrb2.0p25.f003_vgrd_10_m_above_ground.grib2',\n",
    "    '/home/db/metview/JRPdata/gfs2/gfs.t00z.pgrb2.0p25.f003_vgrd_850_mb.grib2',\n",
    "    '/home/db/metview/JRPdata/gfs2/gfs.t00z.pgrb2.0p25.f003_vgrd_925_mb.grib2'\n",
    "]\n",
    "\n",
    "model_name = 'GFS'\n",
    "candidates3 = get_disturbance_candidates_from_split_gribs(grib_files, model_name)\n",
    "print_candidates(candidates3)\n",
    "\n",
    "# getting the time taken for executing the code in seconds\n",
    "time_end = time.time()\n",
    "\n",
    "# Printing the time taken for code execution\n",
    "print(f'Time taken for code execution (seconds): {time_end - time_start:.1f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97826dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3214132b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_and_extract_split_grib_data() time (seconds): 2.3\n",
      "find_mslp_minima_with_closed_isobars() time (seconds): 3.3\n",
      "Calculating Relative vorticity for 850 hPa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/db/.local/lib/python3.9/site-packages/pint/facets/plain/quantity.py:986: RuntimeWarning: invalid value encountered in divide\n",
      "  magnitude = magnitude_op(new_self._magnitude, other._magnitude)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_vorticity() time (seconds): 0.9\n",
      "Finished calculating vorticity\n",
      "find_rv_maximums_in_neighborhoods() time (seconds): 0.0\n",
      "find_gp_250_850_max_thickness() time (seconds): 0.0\n",
      "find_max_wind_925() time (seconds): 0.0\n",
      "add_basin_name() time (seconds): 0.6\n",
      "calc_disturbance_threshold_booleans() time (seconds): 0.0\n",
      "Remove candidates not meeting all criteria, time (seconds): 0.0\n",
      "# 1, WP Basin, Latitude (deg:):   21.2, Longitude (deg):  109.6, MSLP (hPa): 1006.4, 850 RV MAX (*10^-5 1/s): 51.43, 250-850 hPa Thickness (m): 9550.65, 925 hPa WS MAX (m/s):  26.36\n",
      "# 2, EP Basin, Latitude (deg:):   18.0, Longitude (deg): -108.0, MSLP (hPa):  976.6, 850 RV MAX (*10^-5 1/s): 124.60, 250-850 hPa Thickness (m): 9684.65, 925 hPa WS MAX (m/s):  40.30\n",
      "# 3, AL Basin, Latitude (deg:):   13.6, Longitude (deg):  -57.2, MSLP (hPa): 1004.7, 850 RV MAX (*10^-5 1/s): 50.97, 250-850 hPa Thickness (m): 9546.40, 925 hPa WS MAX (m/s):  26.70\n",
      "# 4, AL Basin, Latitude (deg:):   13.6, Longitude (deg):  -56.8, MSLP (hPa): 1004.7, 850 RV MAX (*10^-5 1/s): 50.97, 250-850 hPa Thickness (m): 9546.40, 925 hPa WS MAX (m/s):  26.70\n",
      "Time taken for code execution (seconds): 7.1\n"
     ]
    }
   ],
   "source": [
    "# Get the current time before executing the code\n",
    "time_start = time.time()\n",
    "\n",
    "grib_files = [\n",
    "    '/home/db/metview/JRPdata/ecmwf_oper_hres/20231020000000-0h-oper-fc_10u_sfc.grib2',\n",
    "    '/home/db/metview/JRPdata/ecmwf_oper_hres/20231020000000-0h-oper-fc_10v_sfc.grib2',\n",
    "    '/home/db/metview/JRPdata/ecmwf_oper_hres/20231020000000-0h-oper-fc_gh_250_pl.grib2',\n",
    "    '/home/db/metview/JRPdata/ecmwf_oper_hres/20231020000000-0h-oper-fc_gh_850_pl.grib2',\n",
    "    '/home/db/metview/JRPdata/ecmwf_oper_hres/20231020000000-0h-oper-fc_msl_sfc.grib2',\n",
    "    '/home/db/metview/JRPdata/ecmwf_oper_hres/20231020000000-0h-oper-fc_u_850_pl.grib2',\n",
    "    '/home/db/metview/JRPdata/ecmwf_oper_hres/20231020000000-0h-oper-fc_u_925_pl.grib2',\n",
    "    '/home/db/metview/JRPdata/ecmwf_oper_hres/20231020000000-0h-oper-fc_v_850_pl.grib2',\n",
    "    '/home/db/metview/JRPdata/ecmwf_oper_hres/20231020000000-0h-oper-fc_v_925_pl.grib2'\n",
    "]\n",
    "\n",
    "model_name = 'ECM'\n",
    "candidates4 = get_disturbance_candidates_from_split_gribs(grib_files, model_name)\n",
    "print_candidates(candidates4)\n",
    "\n",
    "# getting the time taken for executing the code in seconds\n",
    "time_end = time.time()\n",
    "\n",
    "# Printing the time taken for code execution\n",
    "print(f'Time taken for code execution (seconds): {time_end - time_start:.1f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8df397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7e83ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/db/metview/JRPdata/cmc-15km/CMC_glb_HGT_ISBL_250_latlon.15x.15_2023102100_P000.grib2',\n",
       " '/home/db/metview/JRPdata/cmc-15km/CMC_glb_HGT_ISBL_850_latlon.15x.15_2023102100_P000.grib2',\n",
       " '/home/db/metview/JRPdata/cmc-15km/CMC_glb_PRMSL_MSL_0_latlon.15x.15_2023102100_P000.grib2',\n",
       " '/home/db/metview/JRPdata/cmc-15km/CMC_glb_UGRD_ISBL_850_latlon.15x.15_2023102100_P000.grib2',\n",
       " '/home/db/metview/JRPdata/cmc-15km/CMC_glb_UGRD_ISBL_925_latlon.15x.15_2023102100_P000.grib2',\n",
       " '/home/db/metview/JRPdata/cmc-15km/CMC_glb_UGRD_TGL_10_latlon.15x.15_2023102100_P000.grib2',\n",
       " '/home/db/metview/JRPdata/cmc-15km/CMC_glb_VGRD_ISBL_800_latlon.15x.15_2023102100_P000.grib2',\n",
       " '/home/db/metview/JRPdata/cmc-15km/CMC_glb_VGRD_ISBL_925_latlon.15x.15_2023102100_P000.grib2',\n",
       " '/home/db/metview/JRPdata/cmc-15km/CMC_glb_VGRD_TGL_10_latlon.15x.15_2023102100_P000.grib2']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"/home/db/metview/JRPdata/cmc-15km/CMC_glb_HGT_ISBL_250_latlon.15x.15_2023102100_P000.grib2\n",
    "/home/db/metview/JRPdata/cmc-15km/CMC_glb_HGT_ISBL_850_latlon.15x.15_2023102100_P000.grib2\n",
    "/home/db/metview/JRPdata/cmc-15km/CMC_glb_PRMSL_MSL_0_latlon.15x.15_2023102100_P000.grib2\n",
    "/home/db/metview/JRPdata/cmc-15km/CMC_glb_UGRD_ISBL_850_latlon.15x.15_2023102100_P000.grib2\n",
    "/home/db/metview/JRPdata/cmc-15km/CMC_glb_UGRD_ISBL_925_latlon.15x.15_2023102100_P000.grib2\n",
    "/home/db/metview/JRPdata/cmc-15km/CMC_glb_UGRD_TGL_10_latlon.15x.15_2023102100_P000.grib2\n",
    "/home/db/metview/JRPdata/cmc-15km/CMC_glb_VGRD_ISBL_800_latlon.15x.15_2023102100_P000.grib2\n",
    "/home/db/metview/JRPdata/cmc-15km/CMC_glb_VGRD_ISBL_925_latlon.15x.15_2023102100_P000.grib2\n",
    "/home/db/metview/JRPdata/cmc-15km/CMC_glb_VGRD_TGL_10_latlon.15x.15_2023102100_P000.grib2\"\"\".split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4f597ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_and_extract_split_grib_data() time (seconds): 35.1\n",
      "find_mslp_minima_with_closed_isobars() time (seconds): 69.1\n",
      "Calculating Relative vorticity for 850 hPa\n",
      "calculate_vorticity() time (seconds): 6.4\n",
      "Finished calculating vorticity\n",
      "find_rv_maximums_in_neighborhoods() time (seconds): 0.0\n",
      "find_gp_250_850_max_thickness() time (seconds): 0.0\n",
      "find_max_wind_925() time (seconds): 0.0\n",
      "add_basin_name() time (seconds): 0.5\n",
      "calc_disturbance_threshold_booleans() time (seconds): 0.0\n",
      "Remove candidates not meeting all criteria, time (seconds): 0.0\n",
      "# 1, EP Basin, Latitude (deg:):    9.0, Longitude (deg):  -96.0, MSLP (hPa): 1006.8, 850 RV MAX (*10^-5 1/s): 32.28, 250-850 hPa Thickness (m): 9538.66, 925 hPa WS MAX (m/s):  16.86\n",
      "# 2, IO Basin, Latitude (deg:):   10.1, Longitude (deg):   59.3, MSLP (hPa): 1003.3, 850 RV MAX (*10^-5 1/s): 64.62, 250-850 hPa Thickness (m): 9554.66, 925 hPa WS MAX (m/s):  22.63\n",
      "# 3, AL Basin, Latitude (deg:):   14.9, Longitude (deg):  -59.7, MSLP (hPa): 1004.0, 850 RV MAX (*10^-5 1/s): 92.04, 250-850 hPa Thickness (m): 9570.91, 925 hPa WS MAX (m/s):  29.53\n",
      "# 4, EP Basin, Latitude (deg:):   20.4, Longitude (deg): -109.8, MSLP (hPa):  981.0, 850 RV MAX (*10^-5 1/s): 152.06, 250-850 hPa Thickness (m): 9736.66, 925 hPa WS MAX (m/s):  45.19\n",
      "Time taken for code execution (seconds): 111.1\n"
     ]
    }
   ],
   "source": [
    "# Get the current time before executing the code\n",
    "time_start = time.time()\n",
    "\n",
    "grib_files = [\n",
    "    '/home/db/metview/JRPdata/cmc-15km/CMC_glb_HGT_ISBL_250_latlon.15x.15_2023102100_P000.grib2',\n",
    "    '/home/db/metview/JRPdata/cmc-15km/CMC_glb_HGT_ISBL_850_latlon.15x.15_2023102100_P000.grib2',\n",
    "    '/home/db/metview/JRPdata/cmc-15km/CMC_glb_PRMSL_MSL_0_latlon.15x.15_2023102100_P000.grib2',\n",
    "    '/home/db/metview/JRPdata/cmc-15km/CMC_glb_UGRD_ISBL_850_latlon.15x.15_2023102100_P000.grib2',\n",
    "    '/home/db/metview/JRPdata/cmc-15km/CMC_glb_UGRD_ISBL_925_latlon.15x.15_2023102100_P000.grib2',\n",
    "    '/home/db/metview/JRPdata/cmc-15km/CMC_glb_UGRD_TGL_10_latlon.15x.15_2023102100_P000.grib2',\n",
    "    '/home/db/metview/JRPdata/cmc-15km/CMC_glb_VGRD_ISBL_850_latlon.15x.15_2023102100_P000.grib2',\n",
    "    '/home/db/metview/JRPdata/cmc-15km/CMC_glb_VGRD_ISBL_925_latlon.15x.15_2023102100_P000.grib2',\n",
    "    '/home/db/metview/JRPdata/cmc-15km/CMC_glb_VGRD_TGL_10_latlon.15x.15_2023102100_P000.grib2'\n",
    "]\n",
    "\n",
    "model_name = 'CMC'\n",
    "candidates5 = get_disturbance_candidates_from_split_gribs(grib_files, model_name)\n",
    "print_candidates(candidates5)\n",
    "\n",
    "# getting the time taken for executing the code in seconds\n",
    "time_end = time.time()\n",
    "\n",
    "# Printing the time taken for code execution\n",
    "print(f'Time taken for code execution (seconds): {time_end - time_start:.1f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e099fd47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f0b5518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/db/metview/JRPdata/ukmet2/agl_u-component-of-wind-surface-adjusted_10.0_2023102512_72.grib',\n",
       " '/home/db/metview/JRPdata/ukmet2/agl_v-component-of-wind-surface-adjusted_10.0_2023102512_72.grib',\n",
       " '/home/db/metview/JRPdata/ukmet2/isbl_geopotential-height_25000.0_2023102512_72.grib',\n",
       " '/home/db/metview/JRPdata/ukmet2/isbl_geopotential-height_85000.0_2023102512_72.grib',\n",
       " '/home/db/metview/JRPdata/ukmet2/isbl_u-component-of-wind_85000.0_2023102512_72.grib',\n",
       " '/home/db/metview/JRPdata/ukmet2/isbl_u-component-of-wind_92500.0_2023102512_72.grib',\n",
       " '/home/db/metview/JRPdata/ukmet2/isbl_v-component-of-wind_85000.0_2023102512_72.grib',\n",
       " '/home/db/metview/JRPdata/ukmet2/isbl_v-component-of-wind_92500.0_2023102512_72.grib',\n",
       " '/home/db/metview/JRPdata/ukmet2/meansea_pressure-reduced-to-msl_2023102512_72.grib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"/home/db/metview/JRPdata/ukmet2/agl_u-component-of-wind-surface-adjusted_10.0_2023102512_72.grib\n",
    "/home/db/metview/JRPdata/ukmet2/agl_v-component-of-wind-surface-adjusted_10.0_2023102512_72.grib\n",
    "/home/db/metview/JRPdata/ukmet2/isbl_geopotential-height_25000.0_2023102512_72.grib\n",
    "/home/db/metview/JRPdata/ukmet2/isbl_geopotential-height_85000.0_2023102512_72.grib\n",
    "/home/db/metview/JRPdata/ukmet2/isbl_u-component-of-wind_85000.0_2023102512_72.grib\n",
    "/home/db/metview/JRPdata/ukmet2/isbl_u-component-of-wind_92500.0_2023102512_72.grib\n",
    "/home/db/metview/JRPdata/ukmet2/isbl_v-component-of-wind_85000.0_2023102512_72.grib\n",
    "/home/db/metview/JRPdata/ukmet2/isbl_v-component-of-wind_92500.0_2023102512_72.grib\n",
    "/home/db/metview/JRPdata/ukmet2/meansea_pressure-reduced-to-msl_2023102512_72.grib\"\"\".split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e48cc673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_and_extract_split_grib_data() time (seconds): 19.8\n",
      "find_mslp_minima_with_closed_isobars() time (seconds): 88.4\n",
      "Calculating Relative vorticity for 850 hPa\n",
      "calculate_vorticity() time (seconds): 10.1\n",
      "Finished calculating vorticity\n",
      "find_rv_maximums_in_neighborhoods() time (seconds): 0.0\n",
      "find_gp_250_850_max_thickness() time (seconds): 0.0\n",
      "find_max_wind_925() time (seconds): 0.0\n",
      "add_basin_name() time (seconds): 0.4\n",
      "calc_disturbance_threshold_booleans() time (seconds): 0.0\n",
      "Remove candidates not meeting all criteria, time (seconds): 0.0\n",
      "# 1, AL Basin, Latitude (deg:):   32.7, Longitude (deg):  -60.0, MSLP (hPa):  994.1, 850 RV MAX (*10^-5 1/s): 113.64, 250-850 hPa Thickness (m): 9550.71, 925 hPa WS MAX (m/s):  34.88\n",
      "Time taken for code execution (seconds): 118.8\n"
     ]
    }
   ],
   "source": [
    "# Get the current time before executing the code\n",
    "time_start = time.time()\n",
    "\n",
    "grib_files = [\n",
    "'/home/db/metview/JRPdata/ukmet2/agl_u-component-of-wind-surface-adjusted_10.0_2023102512_72.grib',\n",
    "'/home/db/metview/JRPdata/ukmet2/agl_v-component-of-wind-surface-adjusted_10.0_2023102512_72.grib',\n",
    "'/home/db/metview/JRPdata/ukmet2/isbl_geopotential-height_25000.0_2023102512_72.grib',\n",
    "'/home/db/metview/JRPdata/ukmet2/isbl_geopotential-height_85000.0_2023102512_72.grib',\n",
    "'/home/db/metview/JRPdata/ukmet2/isbl_u-component-of-wind_85000.0_2023102512_72.grib',\n",
    "'/home/db/metview/JRPdata/ukmet2/isbl_u-component-of-wind_92500.0_2023102512_72.grib',\n",
    "'/home/db/metview/JRPdata/ukmet2/isbl_v-component-of-wind_85000.0_2023102512_72.grib',\n",
    "'/home/db/metview/JRPdata/ukmet2/isbl_v-component-of-wind_92500.0_2023102512_72.grib',\n",
    "'/home/db/metview/JRPdata/ukmet2/meansea_pressure-reduced-to-msl_2023102512_72.grib'\n",
    "]\n",
    "\n",
    "model_name = 'UKM'\n",
    "candidates6 = get_disturbance_candidates_from_split_gribs(grib_files, model_name)\n",
    "print_candidates(candidates6)\n",
    "\n",
    "# getting the time taken for executing the code in seconds\n",
    "time_end = time.time()\n",
    "\n",
    "# Printing the time taken for code execution\n",
    "print(f'\\nTime taken for code execution (seconds): {time_end - time_start:.1f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e227df85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:Vorticity (relative):s**-1 (instant):regular_ll:isobaricInhPa:level 850:fcst time 96 hrs:from 202310190600\n",
      "Parameter Name: Vorticity (relative)\n",
      "Unit: s**-1\n",
      "Level Type: pl\n",
      "Level: 850\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_available_parameters('/home/db/metview/JRPdata/navgem2/US058GMET-GR1mdl.0018_0056_09600F0OF2023101906_0100_008500-000000rltv_vort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb428f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
